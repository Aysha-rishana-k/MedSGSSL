{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25574fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üì¶ Step 1: Import Libraries\n",
    "# ============================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import kagglehub\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab18440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìÅ Step 2: Download and Load Dataset\n",
    "# ============================================\n",
    "\n",
    "# Download NIH Chest X-ray 14 dataset (pre-resized to 224x224)\n",
    "path = kagglehub.dataset_download(\"khanfashee/nih-chest-x-ray-14-224x224-resized\")\n",
    "BASE_PATH = Path(path)\n",
    "print(f\"üìÇ Dataset path: {BASE_PATH}\")\n",
    "\n",
    "# Load labels\n",
    "df_labels = pd.read_csv(BASE_PATH / \"Data_Entry_2017.csv\")\n",
    "images_dir = BASE_PATH / \"images-224\" / \"images-224\"\n",
    "df_labels[\"Image Path\"] = [str(images_dir / p) for p in df_labels[\"Image Index\"].values]\n",
    "\n",
    "# Define disease categories\n",
    "DISEASE_CATEGORIES = [\n",
    "    'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass',\n",
    "    'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema',\n",
    "    'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'\n",
    "]\n",
    "\n",
    "# Create binary columns for each disease\n",
    "for disease in DISEASE_CATEGORIES:\n",
    "    df_labels[disease] = df_labels['Finding Labels'].apply(lambda x: 1 if disease in x else 0)\n",
    "\n",
    "# Validate sample images exist\n",
    "sample_paths = df_labels['Image Path'].sample(200, random_state=42).values\n",
    "missing = [p for p in sample_paths if not os.path.exists(p)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(f\"‚ùå Missing {len(missing)} images! First 3: {missing[:3]}\")\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df_labels):,} images\")\n",
    "print(f\"üìä Disease categories: {len(DISEASE_CATEGORIES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ‚öôÔ∏è Step 3: Configuration\n",
    "# ============================================\n",
    "\n",
    "class Config:\n",
    "    # Model\n",
    "    img_size = 224\n",
    "    feat_dim = 256\n",
    "    proj_dim = 128\n",
    "    \n",
    "    # Training\n",
    "    batch_size = 64\n",
    "    pretrain_epochs = 50\n",
    "    finetune_epochs = 30\n",
    "    lr_pretrain = 1e-3\n",
    "    lr_finetune = 1e-4\n",
    "    temperature = 0.1\n",
    "    \n",
    "    # Data\n",
    "    num_workers = 4\n",
    "    use_subset = False  # Set True for quick testing\n",
    "    subset_size = 10000\n",
    "    \n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration:\")\n",
    "print(f\"   Device: {cfg.device}\")\n",
    "print(f\"   Batch size: {cfg.batch_size}\")\n",
    "print(f\"   Pretrain epochs: {cfg.pretrain_epochs}\")\n",
    "print(f\"   Finetune epochs: {cfg.finetune_epochs}\")\n",
    "\n",
    "# GPU optimizations\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623eda99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üîÑ Step 4: Data Augmentation\n",
    "# ============================================\n",
    "\n",
    "class ChestXrayAugment:\n",
    "    \"\"\"Augmentations for contrastive learning on chest X-rays\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=224):\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        if isinstance(img, np.ndarray):\n",
    "            x = torch.tensor(img, dtype=torch.float32)\n",
    "        else:\n",
    "            x = img.clone()\n",
    "        \n",
    "        # Random horizontal flip\n",
    "        if random.random() < 0.5:\n",
    "            x = torch.flip(x, dims=[2])\n",
    "        \n",
    "        # Random rotation (small angles)\n",
    "        if random.random() < 0.7:\n",
    "            angle = random.uniform(-15, 15)\n",
    "            x = transforms.functional.rotate(x, angle)\n",
    "        \n",
    "        # Brightness adjustment\n",
    "        if random.random() < 0.8:\n",
    "            factor = 1 + random.uniform(-0.2, 0.2)\n",
    "            x = transforms.functional.adjust_brightness(x, factor)\n",
    "        \n",
    "        # Contrast adjustment\n",
    "        if random.random() < 0.8:\n",
    "            factor = 1 + random.uniform(-0.2, 0.2)\n",
    "            x = transforms.functional.adjust_contrast(x, factor)\n",
    "        \n",
    "        # Gaussian noise\n",
    "        if random.random() < 0.5:\n",
    "            noise = torch.randn_like(x) * 0.05\n",
    "            x = torch.clamp(x + noise, 0, 1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "augment = ChestXrayAugment(cfg.img_size)\n",
    "print(\"‚úÖ Augmentation pipeline ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1cf0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üì¶ Step 5: Dataset Classes\n",
    "# ============================================\n",
    "\n",
    "class PretrainDataset(Dataset):\n",
    "    \"\"\"Dataset for SSL pretraining\"\"\"\n",
    "    \n",
    "    def __init__(self, df, transform=None, img_size=224):\n",
    "        self.df = df.copy().reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.img_size = img_size\n",
    "        print(f\"üì¶ PretrainDataset: {len(self.df)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['Image Path']\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img = img.resize((self.img_size, self.img_size), Image.LANCZOS)\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        img = np.expand_dims(img, 0)  # (1, H, W)\n",
    "        \n",
    "        if self.transform:\n",
    "            view1 = self.transform(img)\n",
    "            view2 = self.transform(img)\n",
    "        else:\n",
    "            view1 = torch.tensor(img, dtype=torch.float32)\n",
    "            view2 = torch.tensor(img, dtype=torch.float32)\n",
    "        \n",
    "        return view1, view2\n",
    "\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    \"\"\"Dataset for multi-label classification\"\"\"\n",
    "    \n",
    "    def __init__(self, df, disease_categories, img_size=224):\n",
    "        self.df = df.copy().reset_index(drop=True)\n",
    "        self.disease_categories = disease_categories\n",
    "        self.img_size = img_size\n",
    "        print(f\"üì¶ ClassificationDataset: {len(self.df)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row['Image Path']).convert('L')\n",
    "        img = img.resize((self.img_size, self.img_size), Image.LANCZOS)\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        labels = torch.tensor([row[d] for d in self.disease_categories], dtype=torch.float32)\n",
    "        return img, labels\n",
    "\n",
    "print(\"‚úÖ Dataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983884fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üèóÔ∏è Step 6: Model Architecture\n",
    "# ============================================\n",
    "\n",
    "def conv_block(in_c, out_c, kernel=3, stride=1, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel, stride, padding),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "def residual_block(channels):\n",
    "    return nn.Sequential(\n",
    "        conv_block(channels, channels),\n",
    "        conv_block(channels, channels)\n",
    "    )\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"CNN Encoder for feature extraction\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=1, feat_dim=256):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Stage 1: 224 -> 112\n",
    "            conv_block(in_channels, 64),\n",
    "            residual_block(64),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 2: 112 -> 56\n",
    "            conv_block(64, 128),\n",
    "            residual_block(128),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 3: 56 -> 28\n",
    "            conv_block(128, 256),\n",
    "            residual_block(256),\n",
    "            residual_block(256),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 4: 28 -> 14\n",
    "            conv_block(256, 512),\n",
    "            residual_block(512),\n",
    "            residual_block(512),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 5: 14 -> 1\n",
    "            conv_block(512, 512),\n",
    "            residual_block(512),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, feat_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"Projection head for contrastive learning\"\"\"\n",
    "    \n",
    "    def __init__(self, feat_dim=256, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim),\n",
    "            nn.BatchNorm1d(feat_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feat_dim, proj_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Decoder for reconstruction task\"\"\"\n",
    "    \n",
    "    def __init__(self, feat_dim=256, img_size=224):\n",
    "        super().__init__()\n",
    "        self.init_size = img_size // 32  # 7 for 224\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256 * self.init_size * self.init_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),  # 7->14\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),   # 14->28\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),    # 28->56\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1),    # 56->112\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 4, 2, 1),     # 112->224\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = x.view(z.size(0), 256, self.init_size, self.init_size)\n",
    "        return self.decoder(x)\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"Multi-label classifier\"\"\"\n",
    "    \n",
    "    def __init__(self, feat_dim=256, num_classes=14):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # Returns logits\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder(feat_dim=cfg.feat_dim).to(cfg.device)\n",
    "proj_head = ProjectionHead(cfg.feat_dim, cfg.proj_dim).to(cfg.device)\n",
    "decoder = Decoder(cfg.feat_dim, cfg.img_size).to(cfg.device)\n",
    "\n",
    "total_params = sum(p.numel() for p in encoder.parameters()) + \\\n",
    "               sum(p.numel() for p in proj_head.parameters()) + \\\n",
    "               sum(p.numel() for p in decoder.parameters())\n",
    "\n",
    "print(f\"‚úÖ Models initialized\")\n",
    "print(f\"   Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üî• Step 7: Loss Functions\n",
    "# ============================================\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature=0.1):\n",
    "    \"\"\"NT-Xent contrastive loss\"\"\"\n",
    "    device = z1.device\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    \n",
    "    batch_size = z1.shape[0]\n",
    "    representations = torch.cat([z1, z2], dim=0)\n",
    "    similarity = torch.matmul(representations, representations.T) / temperature\n",
    "    \n",
    "    # Mask self-similarities\n",
    "    mask = torch.eye(2 * batch_size, dtype=torch.bool, device=device)\n",
    "    similarity = similarity.masked_fill(mask, -float('inf'))\n",
    "    \n",
    "    # Labels: positive pairs\n",
    "    labels = torch.cat([torch.arange(batch_size) + batch_size,\n",
    "                        torch.arange(batch_size)]).to(device)\n",
    "    \n",
    "    return F.cross_entropy(similarity, labels)\n",
    "\n",
    "print(\"‚úÖ Loss functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f7f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìä Step 8: Create Data Loaders\n",
    "# ============================================\n",
    "\n",
    "# Train/Val split\n",
    "df_shuffled = df_labels.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_size = int(0.8 * len(df_shuffled))\n",
    "train_df = df_shuffled[:train_size]\n",
    "val_df = df_shuffled[train_size:]\n",
    "\n",
    "if cfg.use_subset:\n",
    "    train_df = train_df.head(cfg.subset_size)\n",
    "    val_df = val_df.head(cfg.subset_size // 4)\n",
    "    print(f\"‚ö° Using subset: {len(train_df)} train, {len(val_df)} val\")\n",
    "\n",
    "# Datasets\n",
    "train_pretrain_ds = PretrainDataset(train_df, transform=augment, img_size=cfg.img_size)\n",
    "train_class_ds = ClassificationDataset(train_df, DISEASE_CATEGORIES, cfg.img_size)\n",
    "val_class_ds = ClassificationDataset(val_df, DISEASE_CATEGORIES, cfg.img_size)\n",
    "\n",
    "# DataLoaders\n",
    "pretrain_loader = DataLoader(\n",
    "    train_pretrain_ds, batch_size=cfg.batch_size, shuffle=True,\n",
    "    num_workers=cfg.num_workers, pin_memory=True, drop_last=True\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_class_ds, batch_size=cfg.batch_size, shuffle=True,\n",
    "    num_workers=cfg.num_workers, pin_memory=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_class_ds, batch_size=cfg.batch_size, shuffle=False,\n",
    "    num_workers=cfg.num_workers, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ DataLoaders ready\")\n",
    "print(f\"   Train batches: {len(pretrain_loader)} (pretrain), {len(train_loader)} (classify)\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb32a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üöÄ Step 9: SSL Pretraining\n",
    "# ============================================\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(proj_head.parameters()) + list(decoder.parameters()),\n",
    "    lr=cfg.lr_pretrain, weight_decay=1e-4\n",
    ")\n",
    "\n",
    "ssl_history = {'loss': [], 'contrastive': [], 'reconstruction': []}\n",
    "\n",
    "print(\"üöÄ Starting SSL Pretraining (Baseline)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for epoch in range(1, cfg.pretrain_epochs + 1):\n",
    "    encoder.train()\n",
    "    proj_head.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_cont = 0\n",
    "    total_recon = 0\n",
    "    \n",
    "    pbar = tqdm(pretrain_loader, desc=f\"Epoch {epoch}/{cfg.pretrain_epochs}\")\n",
    "    for view1, view2 in pbar:\n",
    "        view1 = view1.to(cfg.device)\n",
    "        view2 = view2.to(cfg.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Encode\n",
    "        z1 = encoder(view1)\n",
    "        z2 = encoder(view2)\n",
    "        \n",
    "        # Contrastive loss\n",
    "        p1 = proj_head(z1)\n",
    "        p2 = proj_head(z2)\n",
    "        cont_loss = nt_xent_loss(p1, p2, cfg.temperature)\n",
    "        \n",
    "        # Reconstruction loss\n",
    "        rec1 = decoder(z1)\n",
    "        rec2 = decoder(z2)\n",
    "        recon_loss = (F.mse_loss(rec1, view1) + F.mse_loss(rec2, view2)) / 2\n",
    "        \n",
    "        # Combined loss\n",
    "        loss = cont_loss + 0.5 * recon_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_cont += cont_loss.item()\n",
    "        total_recon += recon_loss.item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # Log epoch metrics\n",
    "    n = len(pretrain_loader)\n",
    "    ssl_history['loss'].append(total_loss / n)\n",
    "    ssl_history['contrastive'].append(total_cont / n)\n",
    "    ssl_history['reconstruction'].append(total_recon / n)\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Loss={total_loss/n:.4f}, Cont={total_cont/n:.4f}, Recon={total_recon/n:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ SSL Pretraining Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìà Step 10: Plot SSL Training Curves\n",
    "# ============================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(ssl_history['loss'], 'b-', linewidth=2)\n",
    "axes[0].set_title('Total Loss', fontsize=12)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(ssl_history['contrastive'], 'r-', linewidth=2)\n",
    "axes[1].set_title('Contrastive Loss', fontsize=12)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(ssl_history['reconstruction'], 'g-', linewidth=2)\n",
    "axes[2].set_title('Reconstruction Loss', fontsize=12)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Baseline SSL Training Curves', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_ssl_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üíæ Step 11: Save Pretrained Model\n",
    "# ============================================\n",
    "\n",
    "torch.save({\n",
    "    'encoder': encoder.state_dict(),\n",
    "    'proj_head': proj_head.state_dict(),\n",
    "    'decoder': decoder.state_dict(),\n",
    "    'config': {\n",
    "        'feat_dim': cfg.feat_dim,\n",
    "        'proj_dim': cfg.proj_dim,\n",
    "        'img_size': cfg.img_size\n",
    "    }\n",
    "}, 'baseline_ssl_pretrained.pth')\n",
    "\n",
    "print(\"üíæ Pretrained model saved: baseline_ssl_pretrained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6fdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üéØ Step 12: Fine-tuning for Classification\n",
    "# ============================================\n",
    "\n",
    "# Freeze encoder\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "encoder.eval()\n",
    "\n",
    "# Initialize classifier\n",
    "classifier = Classifier(cfg.feat_dim, len(DISEASE_CATEGORIES)).to(cfg.device)\n",
    "\n",
    "# Class weights for imbalanced data\n",
    "pos_counts = train_df[DISEASE_CATEGORIES].sum().values\n",
    "neg_counts = len(train_df) - pos_counts\n",
    "pos_weights = torch.tensor(neg_counts / (pos_counts + 1e-6), dtype=torch.float32).to(cfg.device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=cfg.lr_finetune, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5, factor=0.5)\n",
    "\n",
    "finetune_history = {'train_loss': [], 'train_auc': [], 'val_loss': [], 'val_auc': []}\n",
    "best_val_auc = 0\n",
    "\n",
    "print(\"üéØ Starting Fine-tuning\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for epoch in range(1, cfg.finetune_epochs + 1):\n",
    "    # Training\n",
    "    classifier.train()\n",
    "    train_loss = 0\n",
    "    train_preds, train_targets = [], []\n",
    "    \n",
    "    for images, targets in tqdm(train_loader, desc=f\"Train {epoch}/{cfg.finetune_epochs}\"):\n",
    "        images = images.to(cfg.device)\n",
    "        targets = targets.to(cfg.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            features = encoder(images)\n",
    "        logits = classifier(features)\n",
    "        loss = criterion(logits, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_preds.append(torch.sigmoid(logits).detach().cpu())\n",
    "        train_targets.append(targets.cpu())\n",
    "    \n",
    "    # Validation\n",
    "    classifier.eval()\n",
    "    val_loss = 0\n",
    "    val_preds, val_targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images = images.to(cfg.device)\n",
    "            targets = targets.to(cfg.device)\n",
    "            \n",
    "            features = encoder(images)\n",
    "            logits = classifier(features)\n",
    "            loss = criterion(logits, targets)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_preds.append(torch.sigmoid(logits).cpu())\n",
    "            val_targets.append(targets.cpu())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_preds = torch.cat(train_preds).numpy()\n",
    "    train_targets = torch.cat(train_targets).numpy()\n",
    "    val_preds = torch.cat(val_preds).numpy()\n",
    "    val_targets = torch.cat(val_targets).numpy()\n",
    "    \n",
    "    train_auc = np.mean([roc_auc_score(train_targets[:, i], train_preds[:, i]) \n",
    "                         for i in range(len(DISEASE_CATEGORIES)) \n",
    "                         if len(np.unique(train_targets[:, i])) > 1])\n",
    "    val_auc = np.mean([roc_auc_score(val_targets[:, i], val_preds[:, i]) \n",
    "                       for i in range(len(DISEASE_CATEGORIES)) \n",
    "                       if len(np.unique(val_targets[:, i])) > 1])\n",
    "    \n",
    "    # Log\n",
    "    finetune_history['train_loss'].append(train_loss / len(train_loader))\n",
    "    finetune_history['train_auc'].append(train_auc)\n",
    "    finetune_history['val_loss'].append(val_loss / len(val_loader))\n",
    "    finetune_history['val_auc'].append(val_auc)\n",
    "    \n",
    "    scheduler.step(val_auc)\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Train AUC={train_auc:.4f}, Val AUC={val_auc:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        torch.save({\n",
    "            'encoder': encoder.state_dict(),\n",
    "            'classifier': classifier.state_dict(),\n",
    "            'val_auc': val_auc\n",
    "        }, 'baseline_best_model.pth')\n",
    "        print(f\"  ‚úÖ Best model saved! Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nüèÜ Best Validation AUC: {best_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639cff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìä Step 13: Plot Fine-tuning Curves\n",
    "# ============================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(finetune_history['train_loss'], 'b-', label='Train', linewidth=2)\n",
    "axes[0].plot(finetune_history['val_loss'], 'r-', label='Val', linewidth=2)\n",
    "axes[0].set_title('Loss', fontsize=12)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(finetune_history['train_auc'], 'b-', label='Train', linewidth=2)\n",
    "axes[1].plot(finetune_history['val_auc'], 'r-', label='Val', linewidth=2)\n",
    "axes[1].set_title('Mean AUC', fontsize=12)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Baseline Fine-tuning Curves', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_finetune_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìà Step 14: Final Evaluation\n",
    "# ============================================\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('baseline_best_model.pth')\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "classifier.load_state_dict(checkpoint['classifier'])\n",
    "\n",
    "encoder.eval()\n",
    "classifier.eval()\n",
    "\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for images, targets in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        images = images.to(cfg.device)\n",
    "        features = encoder(images)\n",
    "        logits = classifier(features)\n",
    "        all_preds.append(torch.sigmoid(logits).cpu())\n",
    "        all_targets.append(targets)\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "# Per-disease AUC\n",
    "print(\"\\nüìä Per-Disease AUC Scores:\")\n",
    "print(\"=\" * 40)\n",
    "auc_scores = []\n",
    "for i, disease in enumerate(DISEASE_CATEGORIES):\n",
    "    if len(np.unique(all_targets[:, i])) > 1:\n",
    "        auc = roc_auc_score(all_targets[:, i], all_preds[:, i])\n",
    "        auc_scores.append((disease, auc))\n",
    "        print(f\"{disease:20s}: {auc:.4f}\")\n",
    "\n",
    "mean_auc = np.mean([a for _, a in auc_scores])\n",
    "print(f\"\\n{'Mean AUC':20s}: {mean_auc:.4f}\")\n",
    "\n",
    "# Plot AUC bar chart\n",
    "auc_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "diseases, aucs = zip(*auc_scores)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['green' if a >= 0.7 else 'orange' if a >= 0.6 else 'red' for a in aucs]\n",
    "plt.barh(diseases, aucs, color=colors, alpha=0.8)\n",
    "plt.axvline(0.5, color='red', linestyle='--', alpha=0.5, label='Random')\n",
    "plt.axvline(mean_auc, color='blue', linestyle='--', alpha=0.7, label=f'Mean: {mean_auc:.3f}')\n",
    "plt.xlabel('AUC Score')\n",
    "plt.title('Baseline: Per-Disease AUC Performance', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_auc_performance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüèÜ BASELINE RESULTS\")\n",
    "print(f\"   Mean AUC: {mean_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38765e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìù Summary\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù BASELINE SSL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nMethod: Standard SimCLR (NT-Xent + Reconstruction)\")\n",
    "print(f\"Dataset: NIH Chest X-ray 14\")\n",
    "print(f\"Training samples: {len(train_df):,}\")\n",
    "print(f\"Validation samples: {len(val_df):,}\")\n",
    "print(f\"\\nPretraining epochs: {cfg.pretrain_epochs}\")\n",
    "print(f\"Fine-tuning epochs: {cfg.finetune_epochs}\")\n",
    "print(f\"\\nüèÜ Final Mean AUC: {mean_auc:.4f}\")\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\"  - baseline_ssl_pretrained.pth\")\n",
    "print(\"  - baseline_best_model.pth\")\n",
    "print(\"  - baseline_ssl_curves.png\")\n",
    "print(\"  - baseline_finetune_curves.png\")\n",
    "print(\"  - baseline_auc_performance.png\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
