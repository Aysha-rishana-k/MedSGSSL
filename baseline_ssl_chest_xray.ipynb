{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25574fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ“¦ Step 1: Import Libraries\n",
    "# ============================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import kagglehub\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab18440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ“ Step 2: Download and Load Dataset\n",
    "# ============================================\n",
    "\n",
    "# Download NIH Chest X-ray 14 dataset (pre-resized to 224x224)\n",
    "path = kagglehub.dataset_download(\"khanfashee/nih-chest-x-ray-14-224x224-resized\")\n",
    "BASE_PATH = Path(path)\n",
    "print(f\"ðŸ“‚ Dataset path: {BASE_PATH}\")\n",
    "\n",
    "# Load labels\n",
    "df_labels = pd.read_csv(BASE_PATH / \"Data_Entry_2017.csv\")\n",
    "images_dir = BASE_PATH / \"images-224\" / \"images-224\"\n",
    "df_labels[\"Image Path\"] = [str(images_dir / p) for p in df_labels[\"Image Index\"].values]\n",
    "\n",
    "# Define disease categories\n",
    "DISEASE_CATEGORIES = [\n",
    "    'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass',\n",
    "    'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema',\n",
    "    'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'\n",
    "]\n",
    "\n",
    "# Create binary columns for each disease\n",
    "for disease in DISEASE_CATEGORIES:\n",
    "    df_labels[disease] = df_labels['Finding Labels'].apply(lambda x: 1 if disease in x else 0)\n",
    "\n",
    "# Validate sample images exist\n",
    "sample_paths = df_labels['Image Path'].sample(200, random_state=42).values\n",
    "missing = [p for p in sample_paths if not os.path.exists(p)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(f\"âŒ Missing {len(missing)} images! First 3: {missing[:3]}\")\n",
    "\n",
    "print(f\"âœ… Loaded {len(df_labels):,} images\")\n",
    "print(f\"ðŸ“Š Disease categories: {len(DISEASE_CATEGORIES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# âš™ï¸ Step 3: Configuration\n",
    "# ============================================\n",
    "\n",
    "class Config:\n",
    "    # Model\n",
    "    img_size = 224\n",
    "    feat_dim = 256\n",
    "    proj_dim = 128\n",
    "    \n",
    "    # Training (DannyNet-inspired settings)\n",
    "    batch_size = 64                # Same as DannyNet\n",
    "    pretrain_epochs = 50\n",
    "    finetune_epochs = 30\n",
    "    lr_pretrain = 1e-3             # For SSL pretraining\n",
    "    lr_finetune = 5e-5             # âœ… DannyNet uses 5e-5 (was 1e-4)\n",
    "    temperature = 0.1\n",
    "    \n",
    "    # Data\n",
    "    num_workers = 4\n",
    "    use_subset = False  # Set True for quick testing\n",
    "    subset_size = 10000\n",
    "    \n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "print(\"âš™ï¸ Configuration:\")\n",
    "print(f\"   Device: {cfg.device}\")\n",
    "print(f\"   Batch size: {cfg.batch_size}\")\n",
    "print(f\"   Pretrain epochs: {cfg.pretrain_epochs}\")\n",
    "print(f\"   Finetune epochs: {cfg.finetune_epochs}\")\n",
    "print(f\"   LR pretrain: {cfg.lr_pretrain}\")\n",
    "print(f\"   LR finetune: {cfg.lr_finetune} (DannyNet setting)\")\n",
    "\n",
    "# GPU optimizations\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ’¾ Step 3.5: Checkpoint & Resume Configuration\n",
    "# ============================================\n",
    "# âš ï¸ EDIT THIS SECTION WHEN RESUMING AFTER DAYS/WEEKS\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ðŸ”§ RESUME CONFIGURATION - EDIT THESE VALUES WHEN RESUMING  â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# ===== STEP 1: Set your checkpoint dataset name =====\n",
    "# After your first run, save outputs as dataset and put the name here\n",
    "# âš ï¸ Use the EXACT name (lowercase, hyphens) - check /kaggle/input/\n",
    "CHECKPOINT_DATASET_NAME = \"baseline-ssl-checkpoints\"  # Unique for baseline\n",
    "\n",
    "# ===== STEP 2: Set resume flags =====\n",
    "RESUME_SSL_PRETRAINING = True    # Set True to resume SSL pretraining\n",
    "RESUME_FINETUNING = True         # Set True to resume fine-tuning\n",
    "\n",
    "# ===== STEP 3: If resuming, specify which checkpoint to load =====\n",
    "# Leave as \"latest\" to auto-detect, or specify: \"baseline_ssl_epoch20.pth\"\n",
    "SSL_CHECKPOINT_FILE = \"latest\"\n",
    "FINETUNE_CHECKPOINT_FILE = \"latest\"\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                    END OF USER CONFIG                        â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Detect environment\n",
    "IN_KAGGLE = os.path.exists('/kaggle')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    CHECKPOINT_DIR = '/kaggle/working/checkpoints'\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    \n",
    "    print(\"ðŸ” Scanning for checkpoint datasets...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load checkpoints from ALL versions of the dataset (v1, v2, v3, etc.)\n",
    "    # This allows keeping older versions while adding new ones\n",
    "    input_path = '/kaggle/input'\n",
    "    if os.path.exists(input_path):\n",
    "        found_any = False\n",
    "        for dataset_folder in sorted(os.listdir(input_path)):\n",
    "            # Match datasets starting with our checkpoint name (ssl-checkpoints, ssl-checkpoints-v2, etc.)\n",
    "            if dataset_folder.startswith(CHECKPOINT_DATASET_NAME):\n",
    "                dataset_path = os.path.join(input_path, dataset_folder)\n",
    "                if os.path.isdir(dataset_path):\n",
    "                    # Check for .pth files in multiple locations:\n",
    "                    # 1. Directly in dataset folder\n",
    "                    # 2. In 'checkpoints' subdirectory\n",
    "                    # 3. In any subdirectory\n",
    "                    search_paths = [dataset_path]\n",
    "                    \n",
    "                    # Add checkpoints subdirectory if it exists\n",
    "                    checkpoints_subdir = os.path.join(dataset_path, 'checkpoints')\n",
    "                    if os.path.isdir(checkpoints_subdir):\n",
    "                        search_paths.append(checkpoints_subdir)\n",
    "                    \n",
    "                    # Also check any other subdirectories for .pth files\n",
    "                    for item in os.listdir(dataset_path):\n",
    "                        item_path = os.path.join(dataset_path, item)\n",
    "                        if os.path.isdir(item_path) and item != 'checkpoints':\n",
    "                            search_paths.append(item_path)\n",
    "                    \n",
    "                    for search_path in search_paths:\n",
    "                        pth_files = [f for f in os.listdir(search_path) if f.endswith('.pth')]\n",
    "                        if pth_files:\n",
    "                            found_any = True\n",
    "                            rel_path = os.path.relpath(search_path, input_path)\n",
    "                            print(f\"ðŸ“‚ Found checkpoints in: {rel_path}\")\n",
    "                            for f in pth_files:\n",
    "                                src = os.path.join(search_path, f)\n",
    "                                dst = os.path.join(CHECKPOINT_DIR, f)\n",
    "                                if not os.path.exists(dst):\n",
    "                                    shutil.copy2(src, dst)\n",
    "                                    print(f\"   ðŸ“¦ Copied: {f}\")\n",
    "                                else:\n",
    "                                    # Check if source is newer\n",
    "                                    src_time = os.path.getmtime(src)\n",
    "                                    dst_time = os.path.getmtime(dst)\n",
    "                                    if src_time > dst_time:\n",
    "                                        shutil.copy2(src, dst)\n",
    "                                        print(f\"   ðŸ”„ Updated: {f} (newer version)\")\n",
    "        \n",
    "        if not found_any:\n",
    "            print(f\"â„¹ï¸ No checkpoint datasets found matching: {CHECKPOINT_DATASET_NAME}*\")\n",
    "            print(\"   This is normal for a fresh start!\")\n",
    "    \n",
    "    existing = [f for f in os.listdir(CHECKPOINT_DIR) if f.endswith('.pth')]\n",
    "    print(\"=\"*60)\n",
    "    if existing:\n",
    "        print(f\"âœ… Total checkpoints available: {len(existing)}\")\n",
    "    else:\n",
    "        print(f\"â„¹ï¸ Starting fresh - no checkpoints loaded\")\n",
    "        \n",
    "else:\\n",
    "    CHECKPOINT_DIR = './checkpoints'\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# ===== CHECKPOINT UTILITIES =====\n",
    "def save_checkpoint(state, filename):\n",
    "    \"\"\"Save checkpoint with timestamp\"\"\"\n",
    "    filepath = os.path.join(CHECKPOINT_DIR, filename)\n",
    "    state['saved_at'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    torch.save(state, filepath)\n",
    "    print(f\"ðŸ’¾ Saved: {filename}\")\n",
    "    \n",
    "    if IN_KAGGLE:\n",
    "        # Also save to root /kaggle/working/ for easy access\n",
    "        torch.save(state, f'/kaggle/working/{filename}')\n",
    "\n",
    "def load_checkpoint(filename):\n",
    "    \"\"\"Load checkpoint from storage\"\"\"\n",
    "    filepath = os.path.join(CHECKPOINT_DIR, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        checkpoint = torch.load(filepath, map_location=cfg.device, weights_only=False)\n",
    "        saved_at = checkpoint.get('saved_at', 'Unknown')\n",
    "        print(f\"âœ… Loaded: {filename} (saved: {saved_at})\")\n",
    "        return checkpoint\n",
    "    print(f\"âš ï¸ Not found: {filepath}\")\n",
    "    return None\n",
    "\n",
    "def find_latest_checkpoint(prefix):\n",
    "    \"\"\"Find the most recent checkpoint with given prefix\"\"\"\n",
    "    if not os.path.exists(CHECKPOINT_DIR):\n",
    "        return None\n",
    "    \n",
    "    # First check for 'latest' checkpoint\n",
    "    latest_file = f'{prefix}_latest.pth'\n",
    "    if os.path.exists(os.path.join(CHECKPOINT_DIR, latest_file)):\n",
    "        return latest_file\n",
    "    \n",
    "    # Otherwise find highest epoch number\n",
    "    import re\n",
    "    pattern = re.compile(rf'{prefix}_epoch(\\d+)\\.pth')\n",
    "    max_epoch = -1\n",
    "    best_file = None\n",
    "    \n",
    "    for f in os.listdir(CHECKPOINT_DIR):\n",
    "        match = pattern.match(f)\n",
    "        if match:\n",
    "            epoch = int(match.group(1))\n",
    "            if epoch > max_epoch:\n",
    "                max_epoch = epoch\n",
    "                best_file = f\n",
    "    \n",
    "    return best_file\n",
    "\n",
    "def list_checkpoints():\n",
    "    \"\"\"List all available checkpoints with details\"\"\"\n",
    "    print(f\"\\nðŸ“ Checkpoints in {CHECKPOINT_DIR}:\")\n",
    "    if not os.path.exists(CHECKPOINT_DIR):\n",
    "        print(\"   (empty)\")\n",
    "        return []\n",
    "    \n",
    "    files = sorted([f for f in os.listdir(CHECKPOINT_DIR) if f.endswith('.pth')])\n",
    "    if not files:\n",
    "        print(\"   (empty)\")\n",
    "        return []\n",
    "    \n",
    "    for f in files:\n",
    "        filepath = os.path.join(CHECKPOINT_DIR, f)\n",
    "        size = os.path.getsize(filepath) / (1024*1024)\n",
    "        try:\n",
    "            ckpt = torch.load(filepath, map_location='cpu', weights_only=False)\n",
    "            epoch = ckpt.get('epoch', '?')\n",
    "            saved_at = ckpt.get('saved_at', 'Unknown')\n",
    "            print(f\"   ðŸ“¦ {f} | Epoch {epoch} | {size:.1f}MB | {saved_at}\")\n",
    "        except:\n",
    "            print(f\"   ðŸ“¦ {f} | {size:.1f}MB\")\n",
    "    return files\n",
    "\n",
    "def get_training_status():\n",
    "    \"\"\"Get current training progress\"\"\"\n",
    "    ssl_ckpt = find_latest_checkpoint('baseline_ssl')\n",
    "    ft_ckpt = find_latest_checkpoint('baseline_finetune')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š TRAINING STATUS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if ssl_ckpt:\n",
    "        ckpt = torch.load(os.path.join(CHECKPOINT_DIR, ssl_ckpt), map_location='cpu', weights_only=False)\n",
    "        ssl_epoch = ckpt.get('epoch', 0)\n",
    "        print(f\"SSL Pretraining: Epoch {ssl_epoch}/{cfg.pretrain_epochs} \"\n",
    "              f\"({'COMPLETE âœ…' if ssl_epoch >= cfg.pretrain_epochs else 'IN PROGRESS'})\")\n",
    "    else:\n",
    "        print(\"SSL Pretraining: NOT STARTED\")\n",
    "        ssl_epoch = 0\n",
    "    \n",
    "    if ft_ckpt:\n",
    "        ckpt = torch.load(os.path.join(CHECKPOINT_DIR, ft_ckpt), map_location='cpu', weights_only=False)\n",
    "        ft_epoch = ckpt.get('epoch', 0)\n",
    "        best_auc = ckpt.get('best_val_auc', 0)\n",
    "        print(f\"Fine-tuning: Epoch {ft_epoch}/{cfg.finetune_epochs} \"\n",
    "              f\"({'COMPLETE âœ…' if ft_epoch >= cfg.finetune_epochs else 'IN PROGRESS'})\")\n",
    "        print(f\"Best Val AUC: {best_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"Fine-tuning: NOT STARTED\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Show current status\n",
    "print(f\"\\nðŸ”§ Environment: {'Kaggle' if IN_KAGGLE else 'Local'}\")\n",
    "print(f\"ðŸ“‚ Checkpoint directory: {CHECKPOINT_DIR}\")\n",
    "list_checkpoints()\n",
    "get_training_status()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Œ SAVING & RESUMING WORKFLOW:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "After each run on Kaggle:\n",
    "  1. Click 'Save Version' â†’ 'Quick Save'\n",
    "  2. Go to Output tab â†’ '+ New Dataset'\n",
    "  3. Name it: {CHECKPOINT_DATASET_NAME}\n",
    "     (Kaggle will auto-version: {CHECKPOINT_DATASET_NAME}, {CHECKPOINT_DATASET_NAME}-v2, etc.)\n",
    "\n",
    "To resume in a NEW session:\n",
    "  1. Click 'Add Input' (right panel)\n",
    "  2. Select 'Your Datasets' â†’ Add ALL versions of {CHECKPOINT_DATASET_NAME}\n",
    "  3. Run notebook - it will automatically load the latest checkpoints!\n",
    "\"\"\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623eda99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ”„ Step 4: Data Augmentation\n",
    "# ============================================\n",
    "\n",
    "class ChestXrayAugment:\n",
    "    \"\"\"Augmentations for contrastive learning on chest X-rays\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=224):\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        if isinstance(img, np.ndarray):\n",
    "            x = torch.tensor(img, dtype=torch.float32)\n",
    "        else:\n",
    "            x = img.clone()\n",
    "        \n",
    "        # Random horizontal flip\n",
    "        if random.random() < 0.5:\n",
    "            x = torch.flip(x, dims=[2])\n",
    "        \n",
    "        # Random rotation (small angles)\n",
    "        if random.random() < 0.7:\n",
    "            angle = random.uniform(-15, 15)\n",
    "            x = transforms.functional.rotate(x, angle)\n",
    "        \n",
    "        # Brightness adjustment\n",
    "        if random.random() < 0.8:\n",
    "            factor = 1 + random.uniform(-0.2, 0.2)\n",
    "            x = transforms.functional.adjust_brightness(x, factor)\n",
    "        \n",
    "        # Contrast adjustment\n",
    "        if random.random() < 0.8:\n",
    "            factor = 1 + random.uniform(-0.2, 0.2)\n",
    "            x = transforms.functional.adjust_contrast(x, factor)\n",
    "        \n",
    "        # Gaussian noise\n",
    "        if random.random() < 0.5:\n",
    "            noise = torch.randn_like(x) * 0.05\n",
    "            x = torch.clamp(x + noise, 0, 1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "augment = ChestXrayAugment(cfg.img_size)\n",
    "print(\"âœ… Augmentation pipeline ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1cf0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ“¦ Step 5: Dataset Classes\n",
    "# ============================================\n",
    "\n",
    "class PretrainDataset(Dataset):\n",
    "    \"\"\"Dataset for SSL pretraining\"\"\"\n",
    "    \n",
    "    def __init__(self, df, transform=None, img_size=224):\n",
    "        self.df = df.copy().reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.img_size = img_size\n",
    "        print(f\"ðŸ“¦ PretrainDataset: {len(self.df)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['Image Path']\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img = img.resize((self.img_size, self.img_size), Image.LANCZOS)\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        img = np.expand_dims(img, 0)  # (1, H, W)\n",
    "        \n",
    "        if self.transform:\n",
    "            view1 = self.transform(img)\n",
    "            view2 = self.transform(img)\n",
    "        else:\n",
    "            view1 = torch.tensor(img, dtype=torch.float32)\n",
    "            view2 = torch.tensor(img, dtype=torch.float32)\n",
    "        \n",
    "        return view1, view2\n",
    "\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    \"\"\"Dataset for multi-label classification with optional augmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, df, disease_categories, img_size=224, is_training=False):\n",
    "        self.df = df.copy().reset_index(drop=True)\n",
    "        self.disease_categories = disease_categories\n",
    "        self.img_size = img_size\n",
    "        self.is_training = is_training\n",
    "        print(f\"ðŸ“¦ ClassificationDataset: {len(self.df)} samples (training={is_training})\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row['Image Path']).convert('L')\n",
    "        img = img.resize((self.img_size, self.img_size), Image.LANCZOS)\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        # Apply augmentation during training\n",
    "        if self.is_training:\n",
    "            if random.random() < 0.5:\n",
    "                img = torch.flip(img, dims=[2])\n",
    "            if random.random() < 0.5:\n",
    "                angle = random.uniform(-15, 15)\n",
    "                img = transforms.functional.rotate(img, angle)\n",
    "            if random.random() < 0.5:\n",
    "                factor = 1 + random.uniform(-0.2, 0.2)\n",
    "                img = transforms.functional.adjust_brightness(img, factor)\n",
    "            if random.random() < 0.5:\n",
    "                factor = 1 + random.uniform(-0.2, 0.2)\n",
    "                img = transforms.functional.adjust_contrast(img, factor)\n",
    "        \n",
    "        labels = torch.tensor([row[d] for d in self.disease_categories], dtype=torch.float32)\n",
    "        return img, labels\n",
    "\n",
    "print(\"âœ… Dataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983884fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ—ï¸ Step 6: Model Architecture\n",
    "# ============================================\n",
    "\n",
    "def conv_block(in_c, out_c, kernel=3, stride=1, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel, stride, padding),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "def residual_block(channels):\n",
    "    return nn.Sequential(\n",
    "        conv_block(channels, channels),\n",
    "        conv_block(channels, channels)\n",
    "    )\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"CNN Encoder for feature extraction\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=1, feat_dim=256):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Stage 1: 224 -> 112\n",
    "            conv_block(in_channels, 64),\n",
    "            residual_block(64),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 2: 112 -> 56\n",
    "            conv_block(64, 128),\n",
    "            residual_block(128),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 3: 56 -> 28\n",
    "            conv_block(128, 256),\n",
    "            residual_block(256),\n",
    "            residual_block(256),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 4: 28 -> 14\n",
    "            conv_block(256, 512),\n",
    "            residual_block(512),\n",
    "            residual_block(512),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 5: 14 -> 1\n",
    "            conv_block(512, 512),\n",
    "            residual_block(512),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, feat_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"Projection head for contrastive learning\"\"\"\n",
    "    \n",
    "    def __init__(self, feat_dim=256, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim),\n",
    "            nn.BatchNorm1d(feat_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feat_dim, proj_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Decoder for reconstruction task\"\"\"\n",
    "    \n",
    "    def __init__(self, feat_dim=256, img_size=224):\n",
    "        super().__init__()\n",
    "        self.init_size = img_size // 32  # 7 for 224\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256 * self.init_size * self.init_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),  # 7->14\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),   # 14->28\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),    # 28->56\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1),    # 56->112\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 4, 2, 1),     # 112->224\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = x.view(z.size(0), 256, self.init_size, self.init_size)\n",
    "        return self.decoder(x)\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"Multi-label classifier\"\"\"\n",
    "    \n",
    "    def __init__(self, feat_dim=256, num_classes=14):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # Returns logits\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder(feat_dim=cfg.feat_dim).to(cfg.device)\n",
    "proj_head = ProjectionHead(cfg.feat_dim, cfg.proj_dim).to(cfg.device)\n",
    "decoder = Decoder(cfg.feat_dim, cfg.img_size).to(cfg.device)\n",
    "\n",
    "total_params = sum(p.numel() for p in encoder.parameters()) + \\\n",
    "               sum(p.numel() for p in proj_head.parameters()) + \\\n",
    "               sum(p.numel() for p in decoder.parameters())\n",
    "\n",
    "print(f\"âœ… Models initialized\")\n",
    "print(f\"   Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ”¥ Step 7: Loss Functions\n",
    "# ============================================\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature=0.1):\n",
    "    \"\"\"NT-Xent contrastive loss\"\"\"\n",
    "    device = z1.device\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    \n",
    "    batch_size = z1.shape[0]\n",
    "    representations = torch.cat([z1, z2], dim=0)\n",
    "    similarity = torch.matmul(representations, representations.T) / temperature\n",
    "    \n",
    "    # Mask self-similarities\n",
    "    mask = torch.eye(2 * batch_size, dtype=torch.bool, device=device)\n",
    "    similarity = similarity.masked_fill(mask, -float('inf'))\n",
    "    \n",
    "    # Labels: positive pairs\n",
    "    labels = torch.cat([torch.arange(batch_size) + batch_size,\n",
    "                        torch.arange(batch_size)]).to(device)\n",
    "    \n",
    "    return F.cross_entropy(similarity, labels)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss for imbalanced classification (from DannyNet SOTA)\n",
    "    Down-weights easy examples, focuses on hard ones\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1.0, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n",
    "print(\"âœ… Loss functions defined\")\n",
    "print(\"   ðŸŽ¯ NT-Xent: Contrastive loss\")\n",
    "print(\"   ðŸŽ¯ FocalLoss: For class imbalance (Î±=1.0, Î³=2.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f7f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ“Š Step 8: Create Data Loaders (Patient-Level Split)\n",
    "# ============================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# âš ï¸ CRITICAL: Patient-level splitting to prevent data leakage\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ”€ PATIENT-LEVEL SPLITTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "unique_patients = df_labels['Patient ID'].unique()\n",
    "print(f\"Total unique patients: {len(unique_patients):,}\")\n",
    "\n",
    "# Split patients: 93% train, 5% val, 2% test\n",
    "train_val_patients, test_patients = train_test_split(\n",
    "    unique_patients, test_size=0.02, random_state=42\n",
    ")\n",
    "train_patients, val_patients = train_test_split(\n",
    "    train_val_patients, test_size=0.052, random_state=42\n",
    ")\n",
    "\n",
    "# Create dataframes based on patient splits\n",
    "train_df = df_labels[df_labels['Patient ID'].isin(train_patients)].copy()\n",
    "val_df = df_labels[df_labels['Patient ID'].isin(val_patients)].copy()\n",
    "test_df = df_labels[df_labels['Patient ID'].isin(test_patients)].copy()\n",
    "\n",
    "print(f\"âœ“ Train: {len(train_df):,} images from {len(train_patients):,} patients\")\n",
    "print(f\"âœ“ Val: {len(val_df):,} images from {len(val_patients):,} patients\")\n",
    "print(f\"âœ“ Test: {len(test_df):,} images from {len(test_patients):,} patients\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if cfg.use_subset:\n",
    "    train_df = train_df.head(cfg.subset_size)\n",
    "    val_df = val_df.head(cfg.subset_size // 4)\n",
    "    test_df = test_df.head(cfg.subset_size // 8)\n",
    "    print(f\"âš¡ Using subset: {len(train_df)} train, {len(val_df)} val, {len(test_df)} test\")\n",
    "\n",
    "# Datasets - NOW WITH AUGMENTATION FOR TRAINING\n",
    "train_pretrain_ds = PretrainDataset(train_df, transform=augment, img_size=cfg.img_size)\n",
    "train_class_ds = ClassificationDataset(train_df, DISEASE_CATEGORIES, cfg.img_size, is_training=True)\n",
    "val_class_ds = ClassificationDataset(val_df, DISEASE_CATEGORIES, cfg.img_size, is_training=False)\n",
    "test_class_ds = ClassificationDataset(test_df, DISEASE_CATEGORIES, cfg.img_size, is_training=False)\n",
    "\n",
    "# DataLoaders - FAST PIPELINE (like tf.data)\n",
    "# ðŸš€ num_workers: Parallel data loading (like num_parallel_calls)\n",
    "# ðŸš€ pin_memory: Faster CPUâ†’GPU transfer  \n",
    "# ðŸš€ prefetch_factor: Prefetch batches per worker (like prefetch)\n",
    "# ðŸš€ persistent_workers: Keep workers alive between epochs\n",
    "pretrain_loader = DataLoader(\n",
    "    train_pretrain_ds, batch_size=cfg.batch_size, shuffle=True,\n",
    "    num_workers=cfg.num_workers, pin_memory=True, drop_last=True,\n",
    "    prefetch_factor=2, persistent_workers=True if cfg.num_workers > 0 else False\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_class_ds, batch_size=cfg.batch_size, shuffle=True,\n",
    "    num_workers=cfg.num_workers, pin_memory=True, drop_last=True,\n",
    "    prefetch_factor=2, persistent_workers=True if cfg.num_workers > 0 else False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_class_ds, batch_size=cfg.batch_size, shuffle=False,\n",
    "    num_workers=cfg.num_workers, pin_memory=True,\n",
    "    prefetch_factor=2, persistent_workers=True if cfg.num_workers > 0 else False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_class_ds, batch_size=cfg.batch_size, shuffle=False,\n",
    "    num_workers=cfg.num_workers, pin_memory=True,\n",
    "    prefetch_factor=2, persistent_workers=True if cfg.num_workers > 0 else False\n",
    ")\n",
    "\n",
    "print(f\"âœ… DataLoaders ready - FAST PIPELINE (with training augmentation)\")\n",
    "print(f\"   Train batches: {len(pretrain_loader)} (pretrain), {len(train_loader)} (classify)\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")\n",
    "print(f\"   Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb32a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸš€ Step 9: SSL Pretraining\n",
    "# ============================================\n",
    "\n",
    "# Clear GPU cache before training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "optimizer_ssl = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(proj_head.parameters()) + list(decoder.parameters()),\n",
    "    lr=cfg.lr_pretrain, weight_decay=1e-4\n",
    ")\n",
    "\n",
    "ssl_history = {'loss': [], 'contrastive': [], 'reconstruction': []}\n",
    "START_EPOCH = 1\n",
    "\n",
    "# ===== AUTO-RESUME FROM CHECKPOINT =====\n",
    "if RESUME_SSL_PRETRAINING:\n",
    "    if SSL_CHECKPOINT_FILE == \"latest\":\n",
    "        ckpt_file = find_latest_checkpoint('baseline_ssl')\n",
    "    else:\n",
    "        ckpt_file = SSL_CHECKPOINT_FILE\n",
    "    \n",
    "    if ckpt_file:\n",
    "        checkpoint = load_checkpoint(ckpt_file)\n",
    "        if checkpoint:\n",
    "            encoder.load_state_dict(checkpoint['encoder'])\n",
    "            proj_head.load_state_dict(checkpoint['proj_head'])\n",
    "            decoder.load_state_dict(checkpoint['decoder'])\n",
    "            if 'optimizer' in checkpoint:\n",
    "                optimizer_ssl.load_state_dict(checkpoint['optimizer'])\n",
    "            ssl_history = checkpoint.get('ssl_history', ssl_history)\n",
    "            START_EPOCH = checkpoint['epoch'] + 1\n",
    "            print(f\"ðŸ”„ Resuming SSL pretraining from epoch {START_EPOCH}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ RESUME_SSL_PRETRAINING=True but no checkpoint found. Starting fresh.\")\n",
    "\n",
    "if START_EPOCH > cfg.pretrain_epochs:\n",
    "    print(f\"âœ… SSL Pretraining already complete ({cfg.pretrain_epochs} epochs)\")\n",
    "    print(\"   Skipping to next step...\")\n",
    "else:\n",
    "    print(f\"\\nðŸš€ Starting Baseline SSL Pretraining\")\n",
    "    print(f\"   Epochs: {START_EPOCH} â†’ {cfg.pretrain_epochs}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    SAVE_EVERY = 5  # Save every 5 epochs\n",
    "    \n",
    "    for epoch in range(START_EPOCH, cfg.pretrain_epochs + 1):\n",
    "        encoder.train()\n",
    "        proj_head.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        total_cont = 0\n",
    "        total_recon = 0\n",
    "        \n",
    "        loader = tqdm(pretrain_loader, desc=f\"Epoch {epoch}/{cfg.pretrain_epochs}\") if not IN_KAGGLE else pretrain_loader\n",
    "        for view1, view2 in loader:\n",
    "            view1 = view1.to(cfg.device)\n",
    "            view2 = view2.to(cfg.device)\n",
    "            \n",
    "            optimizer_ssl.zero_grad()\n",
    "            \n",
    "            # Encode\n",
    "            z1 = encoder(view1)\n",
    "            z2 = encoder(view2)\n",
    "            \n",
    "            # Contrastive loss\n",
    "            p1 = proj_head(z1)\n",
    "            p2 = proj_head(z2)\n",
    "            cont_loss = nt_xent_loss(p1, p2, cfg.temperature)\n",
    "            \n",
    "            # Reconstruction loss\n",
    "            rec1 = decoder(z1)\n",
    "            rec2 = decoder(z2)\n",
    "            recon_loss = (F.mse_loss(rec1, view1) + F.mse_loss(rec2, view2)) / 2\n",
    "            \n",
    "            # Combined loss\n",
    "            loss = cont_loss + 0.5 * recon_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer_ssl.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_cont += cont_loss.item()\n",
    "            total_recon += recon_loss.item()\n",
    "            \n",
    "            if not IN_KAGGLE:\n",
    "                loader.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "            # Free memory\n",
    "            del z1, z2, p1, p2, rec1, rec2, loss, cont_loss, recon_loss\n",
    "        \n",
    "        # Clear cache at end of epoch\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Log epoch metrics\n",
    "        n = len(pretrain_loader)\n",
    "        ssl_history['loss'].append(total_loss / n)\n",
    "        ssl_history['contrastive'].append(total_cont / n)\n",
    "        ssl_history['reconstruction'].append(total_recon / n)\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Loss={total_loss/n:.4f}, Cont={total_cont/n:.4f}, Recon={total_recon/n:.4f}\")\n",
    "        \n",
    "        # Save checkpoints periodically\n",
    "        if epoch % SAVE_EVERY == 0 or epoch == cfg.pretrain_epochs:\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'encoder': encoder.state_dict(),\n",
    "                'proj_head': proj_head.state_dict(),\n",
    "                'decoder': decoder.state_dict(),\n",
    "                'optimizer': optimizer_ssl.state_dict(),\n",
    "                'ssl_history': ssl_history,\n",
    "                'config': vars(cfg),\n",
    "                'phase': 'ssl_pretraining'\n",
    "            }, 'baseline_ssl_latest.pth')\n",
    "            \n",
    "            save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'encoder': encoder.state_dict(),\n",
    "                'proj_head': proj_head.state_dict(),\n",
    "                'decoder': decoder.state_dict(),\n",
    "                'ssl_history': ssl_history,\n",
    "            }, f'baseline_ssl_epoch{epoch}.pth')\n",
    "    \n",
    "    print(\"\\nâœ… Baseline SSL Pretraining Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ“ˆ Step 10: Plot SSL Training Curves\n",
    "# ============================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(ssl_history['loss'], 'b-', linewidth=2)\n",
    "axes[0].set_title('Total Loss', fontsize=12)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(ssl_history['contrastive'], 'r-', linewidth=2)\n",
    "axes[1].set_title('Contrastive Loss', fontsize=12)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(ssl_history['reconstruction'], 'g-', linewidth=2)\n",
    "axes[2].set_title('Reconstruction Loss', fontsize=12)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Baseline SSL Training Curves', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_ssl_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ’¾ Step 11: Save Pretrained Model\n",
    "# ============================================\n",
    "\n",
    "torch.save({\n",
    "    'encoder': encoder.state_dict(),\n",
    "    'proj_head': proj_head.state_dict(),\n",
    "    'decoder': decoder.state_dict(),\n",
    "    'config': {\n",
    "        'feat_dim': cfg.feat_dim,\n",
    "        'proj_dim': cfg.proj_dim,\n",
    "        'img_size': cfg.img_size\n",
    "    }\n",
    "}, 'baseline_ssl_pretrained.pth')\n",
    "\n",
    "print(\"ðŸ’¾ Pretrained model saved: baseline_ssl_pretrained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6fdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸŽ¯ Step 12: Fine-tuning for Classification\n",
    "# ============================================\n",
    "# KEY IMPROVEMENTS (inspired by DannyNet SOTA):\n",
    "# 1. UNFREEZE encoder with differential learning rate\n",
    "# 2. Use Focal Loss instead of BCE\n",
    "# 3. Use AdamW optimizer\n",
    "# 4. More aggressive LR scheduler\n",
    "# ============================================\n",
    "\n",
    "# âœ… UNFREEZE encoder for fine-tuning (CRITICAL for performance!)\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = True  # UNFROZEN!\n",
    "encoder.train()\n",
    "\n",
    "# Initialize classifier\n",
    "classifier = Classifier(cfg.feat_dim, len(DISEASE_CATEGORIES)).to(cfg.device)\n",
    "\n",
    "# âœ… Use Focal Loss instead of weighted BCE\n",
    "criterion = FocalLoss(alpha=1.0, gamma=2.0)\n",
    "\n",
    "# âœ… Differential learning rates with AdamW\n",
    "encoder_lr = cfg.lr_finetune / 10  # Lower LR for pretrained encoder\n",
    "classifier_lr = cfg.lr_finetune\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': encoder.parameters(), 'lr': encoder_lr},\n",
    "    {'params': classifier.parameters(), 'lr': classifier_lr}\n",
    "], weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', patience=2, factor=0.1, min_lr=1e-7\n",
    ")\n",
    "\n",
    "print(\"ðŸ”§ Fine-tuning Configuration:\")\n",
    "print(f\"   âœ… Encoder: UNFROZEN with LR={encoder_lr:.2e}\")\n",
    "print(f\"   âœ… Classifier LR: {classifier_lr:.2e}\")\n",
    "print(f\"   âœ… Loss: FocalLoss (Î±=1.0, Î³=2.0)\")\n",
    "print(f\"   âœ… Optimizer: AdamW\")\n",
    "\n",
    "finetune_history = {'train_loss': [], 'train_auc': [], 'val_loss': [], 'val_auc': []}\n",
    "best_val_auc = 0\n",
    "FINETUNE_START_EPOCH = 1\n",
    "\n",
    "# ===== AUTO-RESUME FROM CHECKPOINT =====\n",
    "if RESUME_FINETUNING:\n",
    "    if FINETUNE_CHECKPOINT_FILE == \"latest\":\n",
    "        ckpt_file = find_latest_checkpoint('baseline_finetune')\n",
    "    else:\n",
    "        ckpt_file = FINETUNE_CHECKPOINT_FILE\n",
    "    \n",
    "    if ckpt_file:\n",
    "        ft_checkpoint = load_checkpoint(ckpt_file)\n",
    "        if ft_checkpoint:\n",
    "            classifier.load_state_dict(ft_checkpoint['classifier'])\n",
    "            if 'encoder' in ft_checkpoint:\n",
    "                encoder.load_state_dict(ft_checkpoint['encoder'])\n",
    "            if 'optimizer' in ft_checkpoint:\n",
    "                try:\n",
    "                    optimizer.load_state_dict(ft_checkpoint['optimizer'])\n",
    "                except:\n",
    "                    print(\"âš ï¸ Optimizer state incompatible, starting fresh\")\n",
    "            finetune_history = ft_checkpoint.get('finetune_history', finetune_history)\n",
    "            best_val_auc = ft_checkpoint.get('best_val_auc', 0)\n",
    "            FINETUNE_START_EPOCH = ft_checkpoint['epoch'] + 1\n",
    "            print(f\"ðŸ”„ Resuming fine-tuning from epoch {FINETUNE_START_EPOCH}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ RESUME_FINETUNING=True but no checkpoint found. Starting fresh.\")\n",
    "\n",
    "if FINETUNE_START_EPOCH > cfg.finetune_epochs:\n",
    "    print(f\"âœ… Fine-tuning already complete ({cfg.finetune_epochs} epochs)\")\n",
    "    print(f\"   Best Val AUC: {best_val_auc:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nðŸŽ¯ Starting Baseline Fine-tuning (ENCODER UNFROZEN)\")\n",
    "    print(f\"   Epochs: {FINETUNE_START_EPOCH} â†’ {cfg.finetune_epochs}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    SAVE_EVERY_FT = 5  # Save every 5 epochs\n",
    "    \n",
    "    for epoch in range(FINETUNE_START_EPOCH, cfg.finetune_epochs + 1):\n",
    "        # Training - encoder is now also training!\n",
    "        encoder.train()\n",
    "        classifier.train()\n",
    "        train_loss = 0\n",
    "        train_preds, train_targets = [], []\n",
    "        \n",
    "        loader = tqdm(train_loader, desc=f\"Train {epoch}/{cfg.finetune_epochs}\") if not IN_KAGGLE else train_loader\n",
    "        for images, targets in loader:\n",
    "            images = images.to(cfg.device)\n",
    "            targets = targets.to(cfg.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass (encoder is trainable now)\n",
    "            features = encoder(images)\n",
    "            logits = classifier(features)\n",
    "            loss = criterion(logits, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1.0)\n",
    "            torch.nn.utils.clip_grad_norm_(classifier.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_preds.append(torch.sigmoid(logits).detach().cpu())\n",
    "            train_targets.append(targets.cpu())\n",
    "        \n",
    "        # Validation\n",
    "        encoder.eval()\n",
    "        classifier.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_targets = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = images.to(cfg.device)\n",
    "                targets = targets.to(cfg.device)\n",
    "                \n",
    "                features = encoder(images)\n",
    "                logits = classifier(features)\n",
    "                loss = criterion(logits, targets)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_preds.append(torch.sigmoid(logits).cpu())\n",
    "                val_targets.append(targets.cpu())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_preds = torch.cat(train_preds).numpy()\n",
    "        train_targets = torch.cat(train_targets).numpy()\n",
    "        val_preds = torch.cat(val_preds).numpy()\n",
    "        val_targets = torch.cat(val_targets).numpy()\n",
    "        \n",
    "        train_auc = np.mean([roc_auc_score(train_targets[:, i], train_preds[:, i]) \n",
    "                             for i in range(len(DISEASE_CATEGORIES)) \n",
    "                             if len(np.unique(train_targets[:, i])) > 1])\n",
    "        val_auc = np.mean([roc_auc_score(val_targets[:, i], val_preds[:, i]) \n",
    "                           for i in range(len(DISEASE_CATEGORIES)) \n",
    "                           if len(np.unique(val_targets[:, i])) > 1])\n",
    "        \n",
    "        # Log\n",
    "        finetune_history['train_loss'].append(train_loss / len(train_loader))\n",
    "        finetune_history['train_auc'].append(train_auc)\n",
    "        finetune_history['val_loss'].append(val_loss / len(val_loader))\n",
    "        finetune_history['val_auc'].append(val_auc)\n",
    "        \n",
    "        scheduler.step(val_auc)\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Train AUC={train_auc:.4f}, Val AUC={val_auc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            save_checkpoint({\n",
    "                'encoder': encoder.state_dict(),\n",
    "                'classifier': classifier.state_dict(),\n",
    "                'val_auc': val_auc,\n",
    "                'epoch': epoch,\n",
    "                'phase': 'best_model'\n",
    "            }, 'baseline_best_model.pth')\n",
    "            print(f\"  âœ… Best model saved! Val AUC: {val_auc:.4f}\")\n",
    "        \n",
    "        # Save periodic checkpoints\n",
    "        if epoch % SAVE_EVERY_FT == 0 or epoch == cfg.finetune_epochs:\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'encoder': encoder.state_dict(),\n",
    "                'classifier': classifier.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'finetune_history': finetune_history,\n",
    "                'best_val_auc': best_val_auc,\n",
    "                'phase': 'finetuning'\n",
    "            }, 'baseline_finetune_latest.pth')\n",
    "            \n",
    "            save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'encoder': encoder.state_dict(),\n",
    "                'classifier': classifier.state_dict(),\n",
    "                'finetune_history': finetune_history,\n",
    "                'best_val_auc': best_val_auc,\n",
    "                'phase': 'finetuning'\n",
    "            }, f'baseline_finetune_epoch{epoch}.pth')\n",
    "    \n",
    "    print(f\"\\nðŸ† Best Validation AUC: {best_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639cff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ“Š Step 13: Plot Fine-tuning Curves\n",
    "# ============================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(finetune_history['train_loss'], 'b-', label='Train', linewidth=2)\n",
    "axes[0].plot(finetune_history['val_loss'], 'r-', label='Val', linewidth=2)\n",
    "axes[0].set_title('Loss', fontsize=12)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(finetune_history['train_auc'], 'b-', label='Train', linewidth=2)\n",
    "axes[1].plot(finetune_history['val_auc'], 'r-', label='Val', linewidth=2)\n",
    "axes[1].set_title('Mean AUC', fontsize=12)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Baseline Fine-tuning Curves', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_finetune_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ“ˆ Step 14: Final Evaluation on TEST SET\n",
    "# ============================================\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, precision_score, recall_score\n",
    "\n",
    "# Load best model\n",
    "best_model_path = os.path.join(CHECKPOINT_DIR, 'baseline_best_model.pth')\n",
    "checkpoint = torch.load(best_model_path, weights_only=False)\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "classifier.load_state_dict(checkpoint['classifier'])\n",
    "\n",
    "encoder.eval()\n",
    "classifier.eval()\n",
    "\n",
    "# Evaluate on TEST set (not validation!)\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ“Š TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    loader = tqdm(test_loader, desc=\"Evaluating on TEST set\") if not IN_KAGGLE else test_loader\n",
    "    for images, targets in loader:\n",
    "        images = images.to(cfg.device)\n",
    "        features = encoder(images)\n",
    "        logits = classifier(features)\n",
    "        all_preds.append(torch.sigmoid(logits).cpu())\n",
    "        all_targets.append(targets)\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "# Find optimal thresholds per disease\n",
    "print(\"\\nðŸŽ¯ OPTIMAL THRESHOLDS:\")\n",
    "print(\"-\"*40)\n",
    "optimal_thresholds = []\n",
    "for i, disease in enumerate(DISEASE_CATEGORIES):\n",
    "    if len(np.unique(all_targets[:, i])) > 1:\n",
    "        precision, recall, thresholds = precision_recall_curve(all_targets[:, i], all_preds[:, i])\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "    else:\n",
    "        best_threshold = 0.5\n",
    "    optimal_thresholds.append(best_threshold)\n",
    "    print(f\"{disease:20s}: {best_threshold:.3f}\")\n",
    "\n",
    "# Per-disease metrics with optimal thresholds\n",
    "print(\"\\nðŸ“Š PER-DISEASE METRICS (TEST SET):\")\n",
    "print(\"=\"*60)\n",
    "auc_scores = []\n",
    "f1_scores_list = []\n",
    "for i, disease in enumerate(DISEASE_CATEGORIES):\n",
    "    if len(np.unique(all_targets[:, i])) > 1:\n",
    "        auc = roc_auc_score(all_targets[:, i], all_preds[:, i])\n",
    "        pred_binary = (all_preds[:, i] > optimal_thresholds[i]).astype(int)\n",
    "        f1 = f1_score(all_targets[:, i], pred_binary)\n",
    "        prec = precision_score(all_targets[:, i], pred_binary, zero_division=0)\n",
    "        rec = recall_score(all_targets[:, i], pred_binary, zero_division=0)\n",
    "        auc_scores.append(auc)\n",
    "        f1_scores_list.append(f1)\n",
    "        print(f\"{disease:20s}: AUC={auc:.4f} | F1={f1:.4f} | Prec={prec:.4f} | Rec={rec:.4f}\")\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "mean_f1 = np.mean(f1_scores_list)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ðŸ† TEST SET RESULTS:\")\n",
    "print(f\"   Mean AUC: {mean_auc:.4f}\")\n",
    "print(f\"   Mean F1:  {mean_f1:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Plot AUC bar chart\n",
    "auc_data = list(zip(DISEASE_CATEGORIES, auc_scores))\n",
    "auc_data.sort(key=lambda x: x[1], reverse=True)\n",
    "diseases, aucs = zip(*auc_data)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['green' if a >= 0.7 else 'orange' if a >= 0.6 else 'red' for a in aucs]\n",
    "plt.barh(diseases, aucs, color=colors, alpha=0.8)\n",
    "plt.axvline(0.5, color='red', linestyle='--', alpha=0.5, label='Random')\n",
    "plt.axvline(mean_auc, color='blue', linestyle='--', alpha=0.7, label=f'Mean: {mean_auc:.3f}')\n",
    "plt.xlabel('AUC Score')\n",
    "plt.title('Baseline: Per-Disease AUC Performance (TEST SET)', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_auc_performance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38765e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ“ Summary\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ“ BASELINE SSL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nMethod: SimCLR (NT-Xent + Reconstruction) + Unfrozen Fine-tuning\")\n",
    "print(f\"Dataset: NIH Chest X-ray 14\")\n",
    "print(f\"Training samples: {len(train_df):,}\")\n",
    "print(f\"Validation samples: {len(val_df):,}\")\n",
    "print(f\"Test samples: {len(test_df):,}\")\n",
    "print(f\"\\nPretraining epochs: {cfg.pretrain_epochs}\")\n",
    "print(f\"Fine-tuning epochs: {cfg.finetune_epochs}\")\n",
    "print(f\"\\nðŸ”§ Key Improvements Applied:\")\n",
    "print(f\"   âœ… Patient-level train/val/test splits\")\n",
    "print(f\"   âœ… Unfrozen encoder during fine-tuning\")\n",
    "print(f\"   âœ… Focal Loss for class imbalance\")\n",
    "print(f\"   âœ… AdamW optimizer with differential LR\")\n",
    "print(f\"   âœ… Training augmentation\")\n",
    "print(f\"   âœ… Per-disease optimal thresholds\")\n",
    "print(f\"   âœ… Fast DataLoader pipeline\")\n",
    "print(f\"\\nðŸ† TEST SET Mean AUC: {mean_auc:.4f}\")\n",
    "print(f\"ðŸ† TEST SET Mean F1:  {mean_f1:.4f}\")\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\"  - baseline_ssl_pretrained.pth\")\n",
    "print(\"  - baseline_best_model.pth\")\n",
    "print(\"  - baseline_ssl_curves.png\")\n",
    "print(\"  - baseline_finetune_curves.png\")\n",
    "print(\"  - baseline_auc_performance.png\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
