{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a8b2b7",
   "metadata": {},
   "source": [
    "import os\nos.environ['OPENCV_LOG_LEVEL'] = 'SILENT'\n",
    "# Option 2 \u2014 Multi-region (direct classification)\n",
    "\n",
    "Direct classification using MobileNetV2 (no SSL pretraining). Keeps dataset, splits, and augmentations from the original option2 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aedb021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & config\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class CFG:\n",
    "    img_size = 224\n",
    "    batch_size = 32\n",
    "    epochs = 8\n",
    "    lr = 1e-4\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    subset_size = None\n",
    "    encoder_backbone = 'mobilenet_v2'  # 'mobilenet_v2' or 'custom'\n",
    "cfg = CFG()\n",
    "\n",
    "print(cfg.device)\n",
    "print(f\"Encoder backbone: {cfg.encoder_backbone}\")\n",
    "\n",
    "# Specify your custom folder path here\n",
    "CUSTOM_DATA_PATH = \"datasets\"  # Change this to your desired folder\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(CUSTOM_DATA_PATH, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d664912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (same as original option2)\n",
    "try:\n",
    "    import kagglehub\n",
    "    path = kagglehub.dataset_download(\"khanfashee/nih-chest-x-ray-14-224x224-resized\")\n",
    "    BASE_PATH = Path(path)\n",
    "except Exception:\n",
    "    BASE_PATH = Path('.')\n",
    "df = pd.read_csv(BASE_PATH / 'Data_Entry_2017.csv')\n",
    "images_dir = BASE_PATH / 'images-224' / 'images-224'\n",
    "df['Image Path'] = [str(images_dir / p) for p in df['Image Index'].values]\n",
    "\n",
    "DISEASE_CATEGORIES = [\n",
    "    'Atelectasis','Cardiomegaly','Effusion','Infiltration','Mass',\n",
    "    'Nodule','Pneumonia','Pneumothorax','Consolidation','Edema',\n",
    "    'Emphysema','Fibrosis','Pleural_Thickening','Hernia'\n",
    "]\n",
    "for disease in DISEASE_CATEGORIES:\n",
    "    df[disease] = df['Finding Labels'].apply(lambda x: 1 if disease in x else 0)\n",
    "\n",
    "print('Loaded', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient-level split\n",
    "from sklearn.model_selection import train_test_split\n",
    "unique_patients = df['Patient ID'].unique()\n",
    "train_val_patients, test_patients = train_test_split(unique_patients, test_size=0.02, random_state=42)\n",
    "train_patients, val_patients = train_test_split(train_val_patients, test_size=0.052, random_state=42)\n",
    "train_df = df[df['Patient ID'].isin(train_patients)].copy()\n",
    "val_df = df[df['Patient ID'].isin(val_patients)].copy()\n",
    "test_df = df[df['Patient ID'].isin(test_patients)].copy()\n",
    "if cfg.subset_size:\n",
    "    train_df = train_df.head(cfg.subset_size)\n",
    "\n",
    "print('Train/Val/Test:', len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f05ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset (same augmentation pattern used previously)\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, df, disease_categories, img_size=224, is_training=False):\n",
    "        self.df = df.copy().reset_index(drop=True)\n",
    "        self.disease_categories = disease_categories\n",
    "        self.img_size = img_size\n",
    "        self.is_training = is_training\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row['Image Path']).convert('L')\n",
    "        img = img.resize((self.img_size, self.img_size), Image.LANCZOS)\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        if self.is_training:\n",
    "            if np.random.random() > 0.5:\n",
    "                img = np.fliplr(img).copy()\n",
    "            img = img * (0.8 + 0.4 * np.random.random())\n",
    "            mean = img.mean()\n",
    "            img = (img - mean) * (0.8 + 0.4 * np.random.random()) + mean\n",
    "            if np.random.random() > 0.5:\n",
    "                img = rotate(img, np.random.uniform(-10,10), reshape=False, mode='constant', cval=0)\n",
    "            img = np.clip(img, 0, 1)\n",
    "        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)\n",
    "        labels = torch.tensor([row[d] for d in self.disease_categories], dtype=torch.float32)\n",
    "        return img, labels\n",
    "\n",
    "train_ds = ClassificationDataset(train_df, DISEASE_CATEGORIES, cfg.img_size, is_training=True)\n",
    "val_ds = ClassificationDataset(val_df, DISEASE_CATEGORIES, cfg.img_size, is_training=False)\n",
    "test_ds = ClassificationDataset(test_df, DISEASE_CATEGORIES, cfg.img_size, is_training=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print('Data ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38656694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with encoder backbone selection\n",
    "class MobileNetV2Encoder(nn.Module):\n",
    "    \"\"\"MobileNetV2 Encoder backbone for feature extraction\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=1, feat_dim=256, pretrained=True):\n",
    "        super().__init__()\n",
    "        from torchvision import models\n",
    "        \n",
    "        # Load pretrained MobileNetV2 (expects 3 channels)\n",
    "        mobilenet = models.mobilenet_v2(pretrained=pretrained)\n",
    "        \n",
    "        # Adapt for grayscale (1 channel) input\n",
    "        original_conv = mobilenet.features[0][0]\n",
    "        new_conv = nn.Conv2d(in_channels, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        # Initialize with average of RGB weights if converting from pretrained\n",
    "        if pretrained and in_channels == 1:\n",
    "            new_conv.weight.data = original_conv.weight.data.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        mobilenet.features[0][0] = new_conv\n",
    "        \n",
    "        # Extract feature extractor (everything before classifier)\n",
    "        self.features = mobilenet.features\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # MobileNetV2 output is 1280 channels\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, feat_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomEncoder(nn.Module):\n",
    "    \"\"\"Custom CNN encoder backbone\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=1, feat_dim=256):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, feat_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_model(num_classes, backbone='mobilenet_v2', pretrained=True):\n",
    "    \"\"\"Create model with specified backbone\"\"\"\n",
    "    if backbone == 'mobilenet_v2':\n",
    "        mobilenet = models.mobilenet_v2(pretrained=pretrained)\n",
    "        # Adapt first layer for grayscale input\n",
    "        original_conv = mobilenet.features[0][0]\n",
    "        new_conv = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        if pretrained:\n",
    "            new_conv.weight.data = original_conv.weight.data.mean(dim=1, keepdim=True)\n",
    "        mobilenet.features[0][0] = new_conv\n",
    "        \n",
    "        in_features = mobilenet.classifier[1].in_features\n",
    "        mobilenet.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "        return mobilenet\n",
    "    else:  # custom\n",
    "        encoder = CustomEncoder(in_channels=1, feat_dim=512)\n",
    "        classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        return nn.Sequential(encoder, classifier)\n",
    "\n",
    "\n",
    "model = get_model(len(DISEASE_CATEGORIES), cfg.encoder_backbone, pretrained=True).to(cfg.device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "print(f\"Model created with backbone: {cfg.encoder_backbone}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, targets in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_targets, all_preds = [], []\n",
    "    for imgs, targets in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(targets.numpy())\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "    aucs = []\n",
    "    for i in range(all_targets.shape[1]):\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(all_targets[:,i], all_preds[:,i]))\n",
    "        except Exception:\n",
    "            aucs.append(np.nan)\n",
    "    return np.nanmean(aucs), aucs\n",
    "\n",
    "best_auc = 0.0\n",
    "for epoch in range(cfg.epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, cfg.device)\n",
    "    val_auc, _ = validate(model, val_loader, cfg.device)\n",
    "    print(f'Epoch {epoch+1}/{cfg.epochs} - loss {train_loss:.4f} - val AUC {val_auc:.4f}')\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        torch.save(model.state_dict(), f'option2_{cfg.encoder_backbone}_best.pth')\n",
    "\n",
    "print('Done. Best val AUC:', best_auc)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}