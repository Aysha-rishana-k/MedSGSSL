{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "‚úÖ Setup complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "CUSTOM_DATA_PATH = \"datasets\"\n",
    "os.makedirs(CUSTOM_DATA_PATH, exist_ok=True)\n",
    "os.environ['KAGGLEHUB_CACHE'] = CUSTOM_DATA_PATH  # older versions\n",
    "os.environ['KAGGLE_CACHE_DIR'] = CUSTOM_DATA_PATH  # some versions\n",
    "os.environ['KAGGLEHUB_HOME'] = CUSTOM_DATA_PATH    # newer versions\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import kagglehub\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Enable optimizations if available\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    if hasattr(torch.backends.cudnn, 'allow_tf32'):\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "    if hasattr(torch.cuda, 'matmul'):\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "print(\"‚úÖ Setup complete\")\n",
    "\n",
    "# ImageNet normalization for pretrained backbone\n",
    "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "IMAGENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: img_size=224, in_channels=2\n",
      "Pretrain: 50 epochs, Finetune: 100 epochs\n",
      "Batch size: 64, AdamW weight_decay: 1e-05\n",
      "Fine-tune fraction: 0.1 of training data\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    # Data\n",
    "    img_size = 224\n",
    "    in_channels = 2  # grayscale image + segmentation mask\n",
    "    \n",
    "    # Training\n",
    "    batch_size = 64\n",
    "    pretrain_epochs = 50       # was 5 ‚Äî too few for SSL\n",
    "    finetune_epochs = 100\n",
    "    pretrain_lr = 1e-3\n",
    "    finetune_lr = 1e-4\n",
    "    weight_decay = 1e-5\n",
    "    patience = 5               # LR scheduler patience\n",
    "    \n",
    "    # SSL\n",
    "    temperature = 0.5\n",
    "    projection_dim = 128\n",
    "    \n",
    "    # Device\n",
    "    device = device\n",
    "    \n",
    "    # Subset for testing (set to None for full dataset)\n",
    "    subset_size = None\n",
    "    \n",
    "    # Fine-tuning data fraction (1.0 = use all training data)\n",
    "    # Set to e.g. 0.01, 0.1, 0.5 to fine-tune on a subset\n",
    "    finetune_fraction = .1\n",
    "\n",
    "cfg = CFG()\n",
    "print(f\"Configuration: img_size={cfg.img_size}, in_channels={cfg.in_channels}\")\n",
    "print(f\"Pretrain: {cfg.pretrain_epochs} epochs, Finetune: {cfg.finetune_epochs} epochs\")\n",
    "print(f\"Batch size: {cfg.batch_size}, AdamW weight_decay: {cfg.weight_decay}\")\n",
    "print(f\"Fine-tune fraction: {cfg.finetune_fraction} of training data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: datasets/datasets/nih-chest-xrays/data/versions/3\n",
      "Checkpoint directory: checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Check environment and load data\n",
    "IN_KAGGLE = os.path.exists('/kaggle/input')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    data_dir = Path('/kaggle/input/nih-chest-xrays')\n",
    "    checkpoint_dir = Path('/kaggle/working/checkpoints')\n",
    "else:\n",
    "    data_dir = Path(kagglehub.dataset_download('nih-chest-xrays/data'))\n",
    "    checkpoint_dir = Path('./checkpoints')\n",
    "\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Checkpoint directory: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 112120\n",
      "Disease distribution:\n",
      "Atelectasis           11559\n",
      "Cardiomegaly           2776\n",
      "Effusion              13317\n",
      "Infiltration          19894\n",
      "Mass                   5782\n",
      "Nodule                 6331\n",
      "Pneumonia              1431\n",
      "Pneumothorax           5302\n",
      "Consolidation          4667\n",
      "Edema                  2303\n",
      "Emphysema              2516\n",
      "Fibrosis               1686\n",
      "Pleural_Thickening     3385\n",
      "Hernia                  227\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "csv_path = data_dir / 'Data_Entry_2017.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Disease categories\n",
    "disease_categories = [\n",
    "    'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass',\n",
    "    'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema',\n",
    "    'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'\n",
    "]\n",
    "\n",
    "# Create binary labels for each disease\n",
    "for disease in disease_categories:\n",
    "    df[disease] = df['Finding Labels'].apply(lambda x: 1 if disease in x else 0)\n",
    "\n",
    "# Find image paths\n",
    "image_dirs = list(data_dir.glob('images_*/images'))\n",
    "if not image_dirs:\n",
    "    image_dirs = [data_dir / 'images']\n",
    "\n",
    "image_path_map = {}\n",
    "for img_dir in image_dirs:\n",
    "    for img_path in img_dir.glob('*.png'):\n",
    "        image_path_map[img_path.name] = str(img_path)\n",
    "\n",
    "df['Image Path'] = df['Image Index'].map(image_path_map)\n",
    "df = df.dropna(subset=['Image Path'])\n",
    "\n",
    "if cfg.subset_size:\n",
    "    df = df.sample(n=min(cfg.subset_size, len(df)), random_state=42)\n",
    "\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Disease distribution:\")\n",
    "print(df[disease_categories].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Checkpoint & Resume Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Environment: Local\n",
      "üìÇ Checkpoint dir: checkpoints\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üíæ Checkpoint & Resume Configuration\n",
    "# ============================================\n",
    "\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "OPTION_NAME = \"option6\"\n",
    "\n",
    "# ===== RESUME CONFIGURATION =====\n",
    "CHECKPOINT_DATASET_NAME = f\"{OPTION_NAME}-ssl-checkpoints\"  # Unique for Option 6\n",
    "RESUME_SSL_PRETRAINING = True\n",
    "RESUME_FINETUNING = True\n",
    "SSL_CHECKPOINT_FILE = \"latest\"\n",
    "FINETUNE_CHECKPOINT_FILE = \"latest\"\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    CHECKPOINT_DIR = '/kaggle/working/checkpoints'\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    \n",
    "    # Load checkpoints from ALL versions of the dataset\n",
    "    input_path = '/kaggle/input'\n",
    "    if os.path.exists(input_path):\n",
    "        found_any = False\n",
    "        for dataset_folder in sorted(os.listdir(input_path)):\n",
    "            if dataset_folder.startswith(CHECKPOINT_DATASET_NAME):\n",
    "                dataset_path = os.path.join(input_path, dataset_folder)\n",
    "                if os.path.isdir(dataset_path):\n",
    "                    # Check for .pth files in multiple locations\n",
    "                    search_paths = [dataset_path]\n",
    "                    \n",
    "                    checkpoints_subdir = os.path.join(dataset_path, 'checkpoints')\n",
    "                    if os.path.isdir(checkpoints_subdir):\n",
    "                        search_paths.append(checkpoints_subdir)\n",
    "                    \n",
    "                    for item in os.listdir(dataset_path):\n",
    "                        item_path = os.path.join(dataset_path, item)\n",
    "                        if os.path.isdir(item_path) and item != 'checkpoints':\n",
    "                            search_paths.append(item_path)\n",
    "                    \n",
    "                    for search_path in search_paths:\n",
    "                        pth_files = [f for f in os.listdir(search_path) if f.endswith('.pth')]\n",
    "                        if pth_files:\n",
    "                            found_any = True\n",
    "                            rel_path = os.path.relpath(search_path, input_path)\n",
    "                            print(f\"üìÇ Found checkpoints in: {rel_path}\")\n",
    "                            for f in pth_files:\n",
    "                                src = os.path.join(search_path, f)\n",
    "                                dst = os.path.join(CHECKPOINT_DIR, f)\n",
    "                                if not os.path.exists(dst):\n",
    "                                    shutil.copy2(src, dst)\n",
    "                                    print(f\"   üì¶ Copied: {f}\")\n",
    "                                else:\n",
    "                                    src_time = os.path.getmtime(src)\n",
    "                                    dst_time = os.path.getmtime(dst)\n",
    "                                    if src_time > dst_time:\n",
    "                                        shutil.copy2(src, dst)\n",
    "                                        print(f\"   üîÑ Updated: {f} (newer version)\")\n",
    "        \n",
    "        if not found_any:\n",
    "            print(f\"‚ÑπÔ∏è No checkpoint datasets found matching: {CHECKPOINT_DATASET_NAME}*\")\n",
    "    \n",
    "    existing = [f for f in os.listdir(CHECKPOINT_DIR) if f.endswith('.pth')]\n",
    "    if existing:\n",
    "        print(f\"‚úÖ Total checkpoints available: {len(existing)}\")\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è Starting fresh - no checkpoints loaded\")\n",
    "        \n",
    "else:\n",
    "    CHECKPOINT_DIR = str(checkpoint_dir)\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    filepath = os.path.join(CHECKPOINT_DIR, filename)\n",
    "    state['saved_at'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    torch.save(state, filepath)\n",
    "    print(f\"üíæ Saved: {filename}\")\n",
    "    if IN_KAGGLE: torch.save(state, f'/kaggle/working/{filename}')\n",
    "\n",
    "def load_checkpoint(filename):\n",
    "    filepath = os.path.join(CHECKPOINT_DIR, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        checkpoint = torch.load(filepath, map_location=cfg.device, weights_only=False)\n",
    "        print(f\"‚úÖ Loaded: {filename}\")\n",
    "        return checkpoint\n",
    "    return None\n",
    "\n",
    "def find_latest_checkpoint(prefix):\n",
    "    if not os.path.exists(CHECKPOINT_DIR): return None\n",
    "    latest = f'{prefix}_latest.pth'\n",
    "    if os.path.exists(os.path.join(CHECKPOINT_DIR, latest)): return latest\n",
    "    import re\n",
    "    pattern = re.compile(rf'{prefix}_epoch(\\d+)\\.pth')\n",
    "    max_epoch, best = -1, None\n",
    "    for f in os.listdir(CHECKPOINT_DIR):\n",
    "        m = pattern.match(f)\n",
    "        if m and int(m.group(1)) > max_epoch: max_epoch, best = int(m.group(1)), f\n",
    "    return best\n",
    "\n",
    "print(f\"üîß Environment: {'Kaggle' if IN_KAGGLE else 'Local'}\")\n",
    "print(f\"üìÇ Checkpoint dir: {CHECKPOINT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rule-Based Lung Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel mask directory: ./lung_masks/pixel_masks\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Load Pre-Computed Lung Masks (ALL into memory)\n",
    "# ============================================\n",
    "# Masks pre-computed by precompute_lung_masks.ipynb\n",
    "# Loading all masks upfront avoids file I/O in DataLoader workers\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    PIXEL_MASK_DIR = \"/kaggle/working/lung_masks/pixel_masks\"\n",
    "else:\n",
    "    PIXEL_MASK_DIR = \"./lung_masks/pixel_masks\"\n",
    "\n",
    "def load_all_pixel_masks(dataframe, mask_dir=PIXEL_MASK_DIR, img_size=224):\n",
    "    \"\"\"Bulk-load ALL pixel-level lung masks into a dict keyed by Image Index.\"\"\"\n",
    "    masks = {}\n",
    "    missing = 0\n",
    "    for img_name in tqdm(dataframe[\"Image Index\"], desc=\"Loading pixel masks into memory\"):\n",
    "        mask_name = img_name.replace(\".png\", \"\")\n",
    "        mask_path = os.path.join(mask_dir, f\"{mask_name}.npy\")\n",
    "        if os.path.exists(mask_path):\n",
    "            mask = np.load(mask_path)\n",
    "            if mask.dtype == np.uint8:\n",
    "                mask = mask.astype(np.float32) / 255.0\n",
    "            if mask.shape[0] != img_size or mask.shape[1] != img_size:\n",
    "                mask = cv2.resize(mask, (img_size, img_size))\n",
    "            masks[img_name] = mask\n",
    "        else:\n",
    "            masks[img_name] = np.zeros((img_size, img_size), dtype=np.float32)\n",
    "            missing += 1\n",
    "    if missing > 0:\n",
    "        print(f\"‚ö†Ô∏è {missing} masks not found, using zero fallback\")\n",
    "    print(f\"‚úÖ Loaded {len(masks)} pixel masks into memory from {mask_dir}\")\n",
    "    return masks\n",
    "\n",
    "print(f\"Pixel mask directory: {PIXEL_MASK_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset classes defined (masks loaded from memory, no disk I/O in workers)\n"
     ]
    }
   ],
   "source": [
    "class SSLAugmentation:\n",
    "    \"\"\"Augmentations for SSL pretraining.\"\"\"\n",
    "    def __init__(self, img_size=224):\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def __call__(self, image, mask):\n",
    "        # Random horizontal flip (both image and mask)\n",
    "        if np.random.random() > 0.5:\n",
    "            image = np.fliplr(image).copy()\n",
    "            mask = np.fliplr(mask).copy()\n",
    "        \n",
    "        # Random rotation\n",
    "        if np.random.random() > 0.3:\n",
    "            angle = np.random.uniform(-15, 15)\n",
    "            h, w = image.shape[:2]\n",
    "            M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "            image = cv2.warpAffine(image, M, (w, h), borderMode=cv2.BORDER_REPLICATE)\n",
    "            mask = cv2.warpAffine(mask, M, (w, h), borderMode=cv2.BORDER_CONSTANT)\n",
    "        \n",
    "        # Random resized crop (0.8-1.0)\n",
    "        if np.random.random() > 0.3:\n",
    "            h, w = image.shape[:2]\n",
    "            crop_scale = np.random.uniform(0.8, 1.0)\n",
    "            ch, cw = int(h * crop_scale), int(w * crop_scale)\n",
    "            top = np.random.randint(0, h - ch + 1)\n",
    "            left = np.random.randint(0, w - cw + 1)\n",
    "            image = cv2.resize(image[top:top+ch, left:left+cw], (self.img_size, self.img_size))\n",
    "            mask = cv2.resize(mask[top:top+ch, left:left+cw], (self.img_size, self.img_size))\n",
    "        \n",
    "        # Brightness + contrast (image only)\n",
    "        if np.random.random() > 0.3:\n",
    "            alpha = np.random.uniform(0.8, 1.2)\n",
    "            beta = np.random.uniform(-0.1, 0.1)\n",
    "            image = np.clip(alpha * image + beta, 0, 1)\n",
    "        \n",
    "        # Gaussian noise (image only)\n",
    "        if np.random.random() > 0.5:\n",
    "            noise = np.random.normal(0, 0.02, image.shape).astype(np.float32)\n",
    "            image = np.clip(image + noise, 0, 1)\n",
    "        \n",
    "        mask = (mask > 0.5).astype(np.float32)\n",
    "        return image.astype(np.float32), mask.astype(np.float32)\n",
    "\n",
    "\n",
    "def to_2ch_normalized(image, mask):\n",
    "    \"\"\"Stack image+mask as 2-channel tensor with ImageNet-inspired normalization.\"\"\"\n",
    "    gray_mean = 0.449\n",
    "    gray_std = 0.226\n",
    "    image_norm = (image - gray_mean) / gray_std\n",
    "    stacked = np.stack([image_norm, mask], axis=0)  # (2, H, W)\n",
    "    return torch.from_numpy(stacked).float()\n",
    "\n",
    "\n",
    "class SSLPretrainDataset(Dataset):\n",
    "    \"\"\"SSL pretraining dataset ‚Äî uses pre-loaded masks from memory (no disk I/O in workers).\"\"\"\n",
    "    \n",
    "    def __init__(self, df, preloaded_masks, img_size=224):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_size = img_size\n",
    "        self.augmentation = SSLAugmentation(img_size)\n",
    "        self.paths = df['Image Path'].tolist()\n",
    "        self.img_names = df['Image Index'].tolist()\n",
    "        self.preloaded_masks = preloaded_masks\n",
    "        print(f\"üì¶ SSLPretrainDataset: {len(self.df)} samples (masks in memory)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            img = np.zeros((self.img_size, self.img_size), dtype=np.uint8)\n",
    "        img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Get mask from memory (no file I/O!)\n",
    "        mask = self.preloaded_masks[self.img_names[idx]].copy()\n",
    "        if mask.shape != img.shape:\n",
    "            mask = cv2.resize(mask, (self.img_size, self.img_size))\n",
    "        \n",
    "        # Two augmented views\n",
    "        img1, mask1 = self.augmentation(img.copy(), mask.copy())\n",
    "        img2, mask2 = self.augmentation(img.copy(), mask.copy())\n",
    "        \n",
    "        view1 = to_2ch_normalized(img1, mask1)\n",
    "        view2 = to_2ch_normalized(img2, mask2)\n",
    "        return view1, view2\n",
    "\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    \"\"\"Classification dataset ‚Äî uses pre-loaded masks from memory (no disk I/O in workers).\"\"\"\n",
    "    \n",
    "    def __init__(self, df, disease_categories, preloaded_masks, img_size=224, augment=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.disease_categories = disease_categories\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.labels = torch.tensor(df[disease_categories].values.astype(np.float32))\n",
    "        self.paths = df['Image Path'].tolist()\n",
    "        self.img_names = df['Image Index'].tolist()\n",
    "        self.preloaded_masks = preloaded_masks\n",
    "        print(f\"üì¶ ClassificationDataset: {len(self.df)} samples (augment={augment}, masks in memory)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            img = np.zeros((self.img_size, self.img_size), dtype=np.uint8)\n",
    "        img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Get mask from memory (no file I/O!)\n",
    "        mask = self.preloaded_masks[self.img_names[idx]].copy()\n",
    "        if mask.shape != img.shape:\n",
    "            mask = cv2.resize(mask, (self.img_size, self.img_size))\n",
    "        \n",
    "        if self.augment:\n",
    "            if np.random.random() > 0.5:\n",
    "                img = np.fliplr(img).copy()\n",
    "                mask = np.fliplr(mask).copy()\n",
    "            alpha = np.random.uniform(0.9, 1.1)\n",
    "            beta = np.random.uniform(-0.05, 0.05)\n",
    "            img = np.clip(alpha * img + beta, 0, 1)\n",
    "            if np.random.random() > 0.5:\n",
    "                h, w = img.shape[:2]\n",
    "                crop_scale = np.random.uniform(0.85, 1.0)\n",
    "                ch, cw = int(h * crop_scale), int(w * crop_scale)\n",
    "                top = np.random.randint(0, h - ch + 1)\n",
    "                left = np.random.randint(0, w - cw + 1)\n",
    "                img = cv2.resize(img[top:top+ch, left:left+cw], (self.img_size, self.img_size))\n",
    "                mask = cv2.resize(mask[top:top+ch, left:left+cw], (self.img_size, self.img_size))\n",
    "        \n",
    "        mask = (mask > 0.5).astype(np.float32)\n",
    "        tensor = to_2ch_normalized(img, mask)\n",
    "        return tensor, self.labels[idx]\n",
    "\n",
    "\n",
    "print(\"‚úÖ Dataset classes defined (masks loaded from memory, no disk I/O in workers)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model classes defined\n"
     ]
    }
   ],
   "source": [
    "def get_resnet50_multichannel(in_channels=2, pretrained=True):\n",
    "    \"\"\"\n",
    "    Create a ResNet50 backbone modified for 2-channel input.\n",
    "    Adapts pretrained weights by averaging RGB channels.\n",
    "    \"\"\"\n",
    "    model = models.resnet50(pretrained=pretrained)\n",
    "    \n",
    "    # Get original first conv layer\n",
    "    original_conv = model.conv1\n",
    "    \n",
    "    # Create new conv layer with desired input channels\n",
    "    new_conv = nn.Conv2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=original_conv.out_channels,\n",
    "        kernel_size=original_conv.kernel_size,\n",
    "        stride=original_conv.stride,\n",
    "        padding=original_conv.padding,\n",
    "        bias=original_conv.bias is not None\n",
    "    )\n",
    "    \n",
    "    # Initialize weights from pretrained model\n",
    "    with torch.no_grad():\n",
    "        if pretrained:\n",
    "            # Average the RGB weights and replicate for each input channel\n",
    "            original_weights = original_conv.weight.data\n",
    "            avg_weight = original_weights.mean(dim=1, keepdim=True)\n",
    "            new_conv.weight.data = torch.cat([avg_weight] * in_channels, dim=1)\n",
    "            \n",
    "            if original_conv.bias is not None:\n",
    "                new_conv.bias.data = original_conv.bias.data.clone()\n",
    "    \n",
    "    model.conv1 = new_conv\n",
    "    return model\n",
    "\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"Projection head for contrastive learning.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_dim, hidden_dim=512, out_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SSLModel(nn.Module):\n",
    "    \"\"\"SSL model with ResNet50 backbone and projection head.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=2, projection_dim=128, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Backbone\n",
    "        self.backbone = get_resnet50_multichannel(in_channels, pretrained)\n",
    "        self.feature_dim = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        \n",
    "        # Projection head for SSL\n",
    "        self.projection = ProjectionHead(self.feature_dim, out_dim=projection_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        projections = self.projection(features)\n",
    "        return F.normalize(projections, dim=1)\n",
    "    \n",
    "    def get_features(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    \"\"\"Classification model using pretrained SSL backbone.\"\"\"\n",
    "    \n",
    "    def __init__(self, ssl_model, num_classes=14, freeze_backbone=False):\n",
    "        super().__init__()\n",
    "        self.backbone = ssl_model.backbone\n",
    "        self.feature_dim = ssl_model.feature_dim\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.feature_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "print(\"‚úÖ Model classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Contrastive loss defined\n",
      "‚úÖ Loss functions: NTXentLoss, FocalLoss\n"
     ]
    }
   ],
   "source": [
    "class NTXentLoss(nn.Module):\n",
    "    \"\"\"NT-Xent loss for contrastive learning (SimCLR).\"\"\"\n",
    "    \n",
    "    def __init__(self, temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def forward(self, z1, z2):\n",
    "        batch_size = z1.shape[0]\n",
    "        \n",
    "        # Concatenate representations\n",
    "        z = torch.cat([z1, z2], dim=0)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        sim = torch.mm(z, z.t()) / self.temperature\n",
    "        \n",
    "        # Create mask for positive pairs\n",
    "        mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n",
    "        \n",
    "        # Mask out self-similarities\n",
    "        sim.masked_fill_(mask, float('-inf'))\n",
    "        \n",
    "        # Labels: positive pairs are at positions batch_size apart\n",
    "        labels = torch.cat([\n",
    "            torch.arange(batch_size, 2 * batch_size),\n",
    "            torch.arange(batch_size)\n",
    "        ]).to(z.device)\n",
    "        \n",
    "        loss = F.cross_entropy(sim, labels)\n",
    "        return loss\n",
    "\n",
    "print(\"‚úÖ Contrastive loss defined\")\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for class-imbalanced multi-label classification.\"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        bce = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "        pt = torch.exp(-bce)\n",
    "        focal = self.alpha * (1 - pt) ** self.gamma * bce\n",
    "        return focal.mean()\n",
    "\n",
    "print(\"‚úÖ Loss functions: NTXentLoss, FocalLoss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training functions defined\n"
     ]
    }
   ],
   "source": [
    "def pretrain_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    \"\"\"Run one pretraining epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Pretraining\")\n",
    "    for view1, view2 in pbar:\n",
    "        view1, view2 = view1.to(device), view2.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        z1 = model(view1)\n",
    "        z2 = model(view2)\n",
    "        \n",
    "        loss = criterion(z1, z2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def finetune_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    \"\"\"Run one fine-tuning epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Fine-tuning\")\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"Evaluate model and return AUC scores.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        images = images.to(device)\n",
    "        outputs = torch.sigmoid(model(images))\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    # Calculate AUC for each disease\n",
    "    aucs = []\n",
    "    for i in range(all_labels.shape[1]):\n",
    "        if all_labels[:, i].sum() > 0:  # Only if there are positive samples\n",
    "            auc = roc_auc_score(all_labels[:, i], all_preds[:, i])\n",
    "            aucs.append(auc)\n",
    "        else:\n",
    "            aucs.append(0.5)\n",
    "    \n",
    "    return np.mean(aucs), aucs\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÄ PATIENT-LEVEL SPLITTING\n",
      "============================================================\n",
      "Total unique patients: 30,805\n",
      "‚úì Train: 103,847 images from 28,618 patients\n",
      "‚úì Val: 5,974 images from 1,570 patients\n",
      "‚úì Test: 2,299 images from 617 patients\n",
      "\n",
      "üî¨ FINE-TUNING DATA SUBSET\n",
      "   Fraction: 0.1 (10.0%)\n",
      "   Finetune: 10,232 images from 2,861 patients\n",
      "   (SSL pretraining still uses all 103,847 training images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pixel masks into memory: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112120/112120 [00:29<00:00, 3838.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 112120 pixel masks into memory from ./lung_masks/pixel_masks\n",
      "üì¶ SSLPretrainDataset: 103847 samples (masks in memory)\n",
      "üì¶ ClassificationDataset: 10232 samples (augment=True, masks in memory)\n",
      "üì¶ ClassificationDataset: 5974 samples (augment=False, masks in memory)\n",
      "üì¶ ClassificationDataset: 2299 samples (augment=False, masks in memory)\n",
      "üì¶ DataLoaders: num_workers=8, pin_memory=True\n",
      "‚úÖ Data prepared with patient-level splitting\n"
     ]
    }
   ],
   "source": [
    "# Patient-level splitting (prevents data leakage)\n",
    "print(\"üîÄ PATIENT-LEVEL SPLITTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "unique_patients = df['Patient ID'].unique()\n",
    "print(f\"Total unique patients: {len(unique_patients):,}\")\n",
    "\n",
    "train_val_patients, test_patients = train_test_split(\n",
    "    unique_patients, test_size=0.02, random_state=42)\n",
    "train_patients, val_patients = train_test_split(\n",
    "    train_val_patients, test_size=0.052, random_state=42)\n",
    "\n",
    "train_df = df[df['Patient ID'].isin(train_patients)].copy()\n",
    "val_df = df[df['Patient ID'].isin(val_patients)].copy()\n",
    "test_df = df[df['Patient ID'].isin(test_patients)].copy()\n",
    "\n",
    "print(f\"‚úì Train: {len(train_df):,} images from {len(train_patients):,} patients\")\n",
    "print(f\"‚úì Val: {len(val_df):,} images from {len(val_patients):,} patients\")\n",
    "print(f\"‚úì Test: {len(test_df):,} images from {len(test_patients):,} patients\")\n",
    "\n",
    "# ‚îÄ‚îÄ Subsample training data for fine-tuning (patient-level) ‚îÄ‚îÄ\n",
    "if cfg.finetune_fraction < 1.0:\n",
    "    n_finetune_patients = max(1, int(len(train_patients) * cfg.finetune_fraction))\n",
    "    rng = np.random.RandomState(42)\n",
    "    finetune_patient_indices = rng.choice(len(train_patients), size=n_finetune_patients, replace=False)\n",
    "    finetune_patients = train_patients[finetune_patient_indices]\n",
    "    finetune_train_df = train_df[train_df['Patient ID'].isin(finetune_patients)].copy()\n",
    "    print(f\"\\nüî¨ FINE-TUNING DATA SUBSET\")\n",
    "    print(f\"   Fraction: {cfg.finetune_fraction} ({cfg.finetune_fraction*100:.1f}%)\")\n",
    "    print(f\"   Finetune: {len(finetune_train_df):,} images from {n_finetune_patients:,} patients\")\n",
    "    print(f\"   (SSL pretraining still uses all {len(train_df):,} training images)\")\n",
    "else:\n",
    "    finetune_train_df = train_df\n",
    "    print(f\"\\nüî¨ Fine-tuning uses all {len(train_df):,} training images (fraction=1.0)\")\n",
    "\n",
    "# ‚îÄ‚îÄ Bulk-load ALL masks into memory (eliminates disk I/O in DataLoader workers) ‚îÄ‚îÄ\n",
    "all_masks = load_all_pixel_masks(df, img_size=cfg.img_size)\n",
    "\n",
    "# Create datasets (pass preloaded masks)\n",
    "pretrain_dataset = SSLPretrainDataset(train_df, all_masks, img_size=cfg.img_size)\n",
    "train_dataset = ClassificationDataset(finetune_train_df, disease_categories, all_masks, img_size=cfg.img_size, augment=True)\n",
    "val_dataset = ClassificationDataset(val_df, disease_categories, all_masks, img_size=cfg.img_size, augment=False)\n",
    "test_dataset = ClassificationDataset(test_df, disease_categories, all_masks, img_size=cfg.img_size, augment=False)\n",
    "\n",
    "# DataLoaders\n",
    "# Keep num_workers low (2) to avoid OOM-induced worker crashes on Kaggle\n",
    "_nw = 8\n",
    "_pin = torch.cuda.is_available()\n",
    "pretrain_loader = DataLoader(pretrain_dataset, batch_size=cfg.batch_size, shuffle=True,\n",
    "    num_workers=_nw, pin_memory=_pin, persistent_workers=_nw > 0)\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True,\n",
    "    num_workers=_nw, pin_memory=_pin, persistent_workers=_nw > 0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=cfg.batch_size, shuffle=False,\n",
    "    num_workers=_nw, pin_memory=_pin, persistent_workers=_nw > 0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False,\n",
    "    num_workers=_nw, pin_memory=_pin, persistent_workers=_nw > 0)\n",
    "print(f\"üì¶ DataLoaders: num_workers={_nw}, pin_memory={_pin}\")\n",
    "\n",
    "print(\"‚úÖ Data prepared with patient-level splitting\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. SSL Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSL Model parameters: 24,620,672\n",
      "Optimizer: AdamW, LR: 0.001, Schedule: CosineAnnealing\n",
      "‚ö†Ô∏è No SSL checkpoint found. Starting fresh.\n",
      "\n",
      "üöÄ Starting SSL Pretraining!\n",
      "   Epochs: 1 ‚Üí 50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining:   0%|          | 0/1623 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Initialize SSL model\n",
    "ssl_model = SSLModel(\n",
    "    in_channels=cfg.in_channels,\n",
    "    projection_dim=cfg.projection_dim,\n",
    "    pretrained=True\n",
    ").to(cfg.device)\n",
    "\n",
    "# Loss and optimizer\n",
    "ssl_criterion = NTXentLoss(temperature=cfg.temperature)\n",
    "ssl_optimizer = optim.AdamW(ssl_model.parameters(), lr=cfg.pretrain_lr, weight_decay=cfg.weight_decay)\n",
    "ssl_scheduler = optim.lr_scheduler.CosineAnnealingLR(ssl_optimizer, T_max=cfg.pretrain_epochs, eta_min=1e-6)\n",
    "\n",
    "print(f\"SSL Model parameters: {sum(p.numel() for p in ssl_model.parameters()):,}\")\n",
    "print(f\"Optimizer: AdamW, LR: {cfg.pretrain_lr}, Schedule: CosineAnnealing\")\n",
    "\n",
    "pretrain_losses = []\n",
    "START_EPOCH = 1\n",
    "\n",
    "if RESUME_SSL_PRETRAINING:\n",
    "    ckpt_file = find_latest_checkpoint(f'{OPTION_NAME}_ssl') if SSL_CHECKPOINT_FILE == \"latest\" else SSL_CHECKPOINT_FILE\n",
    "    if ckpt_file:\n",
    "        checkpoint = load_checkpoint(ckpt_file)\n",
    "        if checkpoint:\n",
    "            ssl_model.load_state_dict(checkpoint['model'])\n",
    "            if 'optimizer' in checkpoint: ssl_optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            if 'scheduler' in checkpoint: ssl_scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "            pretrain_losses = checkpoint.get('pretrain_losses', pretrain_losses)\n",
    "            START_EPOCH = checkpoint['epoch'] + 1\n",
    "            print(f\"üîÑ Resuming SSL pretraining from epoch {START_EPOCH}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No SSL checkpoint found. Starting fresh.\")\n",
    "\n",
    "if START_EPOCH > cfg.pretrain_epochs:\n",
    "    print(f\"‚úÖ SSL Pretraining already complete ({cfg.pretrain_epochs} epochs)\")\n",
    "else:\n",
    "    print(f\"\\nüöÄ Starting SSL Pretraining!\")\n",
    "    print(f\"   Epochs: {START_EPOCH} ‚Üí {cfg.pretrain_epochs}\")\n",
    "    print(\"=\" * 60)\n",
    "    SAVE_EVERY = 5\n",
    "    \n",
    "    for epoch in range(START_EPOCH, cfg.pretrain_epochs + 1):\n",
    "        loss = pretrain_epoch(ssl_model, pretrain_loader, ssl_optimizer, ssl_criterion, cfg.device)\n",
    "        ssl_scheduler.step()\n",
    "        pretrain_losses.append(loss)\n",
    "        print(f\"Epoch {epoch}/{cfg.pretrain_epochs} - Loss: {loss:.4f} - LR: {ssl_scheduler.get_last_lr()[0]:.6f}\")\n",
    "        \n",
    "        if epoch % SAVE_EVERY == 0 or epoch == cfg.pretrain_epochs:\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch, 'model': ssl_model.state_dict(),\n",
    "                'optimizer': ssl_optimizer.state_dict(),\n",
    "                'scheduler': ssl_scheduler.state_dict(),\n",
    "                'pretrain_losses': pretrain_losses,\n",
    "            }, f'{OPTION_NAME}_ssl_latest.pth')\n",
    "        if epoch % SAVE_EVERY == 0 or epoch == cfg.pretrain_epochs:\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch, 'model': ssl_model.state_dict(),\n",
    "                'pretrain_losses': pretrain_losses,\n",
    "            }, f'{OPTION_NAME}_ssl_epoch{epoch}.pth')\n",
    "    \n",
    "    # Also save with the legacy filename for compatibility\n",
    "    torch.save(ssl_model.state_dict(), checkpoint_dir / 'option6_ssl_pretrained.pth')\n",
    "    print(\"\\n‚úÖ SSL Pretraining complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classification model with pretrained backbone\n",
    "classifier = ClassificationModel(\n",
    "    ssl_model,\n",
    "    num_classes=len(disease_categories),\n",
    "    freeze_backbone=False\n",
    ").to(cfg.device)\n",
    "\n",
    "# FocalLoss + AdamW + ReduceLROnPlateau\n",
    "criterion = FocalLoss(alpha=1, gamma=2)\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': classifier.backbone.parameters(), 'lr': cfg.finetune_lr * 0.1},\n",
    "    {'params': classifier.classifier.parameters(), 'lr': cfg.finetune_lr},\n",
    "], weight_decay=cfg.weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=cfg.patience)\n",
    "\n",
    "print(f\"Classifier parameters: {sum(p.numel() for p in classifier.parameters()):,}\")\n",
    "print(\"Optimizer: AdamW (differential LR), Loss: FocalLoss\")\n",
    "\n",
    "best_auc = 0\n",
    "train_losses = []\n",
    "val_aucs = []\n",
    "patience_counter = 0\n",
    "FINETUNE_START_EPOCH = 1\n",
    "\n",
    "if RESUME_FINETUNING:\n",
    "    ckpt_file = find_latest_checkpoint(f'{OPTION_NAME}_finetune') if FINETUNE_CHECKPOINT_FILE == \"latest\" else FINETUNE_CHECKPOINT_FILE\n",
    "    if ckpt_file:\n",
    "        ft_ckpt = load_checkpoint(ckpt_file)\n",
    "        if ft_ckpt:\n",
    "            classifier.load_state_dict(ft_ckpt['classifier'])\n",
    "            if 'optimizer' in ft_ckpt:\n",
    "                try:\n",
    "                    optimizer.load_state_dict(ft_ckpt['optimizer'])\n",
    "                except:\n",
    "                    print(\"‚ö†Ô∏è Optimizer state incompatible, starting fresh\")\n",
    "            if 'scheduler' in ft_ckpt:\n",
    "                try:\n",
    "                    scheduler.load_state_dict(ft_ckpt['scheduler'])\n",
    "                except:\n",
    "                    print(\"‚ö†Ô∏è Scheduler state incompatible, starting fresh\")\n",
    "            train_losses = ft_ckpt.get('train_losses', train_losses)\n",
    "            val_aucs = ft_ckpt.get('val_aucs', val_aucs)\n",
    "            best_auc = ft_ckpt.get('best_auc', 0)\n",
    "            patience_counter = ft_ckpt.get('patience_counter', 0)\n",
    "            FINETUNE_START_EPOCH = ft_ckpt['epoch'] + 1\n",
    "            print(f\"üîÑ Resuming fine-tuning from epoch {FINETUNE_START_EPOCH} (best AUC: {best_auc:.4f})\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No fine-tuning checkpoint found. Starting fresh.\")\n",
    "\n",
    "if FINETUNE_START_EPOCH > cfg.finetune_epochs:\n",
    "    print(f\"‚úÖ Fine-tuning already complete ({cfg.finetune_epochs} epochs)\")\n",
    "else:\n",
    "    print(f\"\\nüéØ Starting Fine-tuning\")\n",
    "    print(f\"   Epochs: {FINETUNE_START_EPOCH} ‚Üí {cfg.finetune_epochs}\")\n",
    "    print(f\"   Training data: {len(train_loader.dataset):,} samples (fraction={cfg.finetune_fraction})\")\n",
    "    print(\"=\" * 50)\n",
    "    SAVE_EVERY = 5\n",
    "    \n",
    "    for epoch in range(FINETUNE_START_EPOCH, cfg.finetune_epochs + 1):\n",
    "        train_loss = finetune_epoch(classifier, train_loader, optimizer, criterion, cfg.device)\n",
    "        val_auc, _ = evaluate(classifier, val_loader, cfg.device)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_aucs.append(val_auc)\n",
    "        scheduler.step(val_auc)\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch}/{cfg.finetune_epochs} - Loss: {train_loss:.4f}, Val AUC: {val_auc:.4f}, LR: {current_lr:.2e}\")\n",
    "        \n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            torch.save(classifier.state_dict(), checkpoint_dir / 'option6_ssl_best.pth')\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch, 'classifier': classifier.state_dict(),\n",
    "                'val_auc': val_auc,\n",
    "            }, f'{OPTION_NAME}_best_model.pth')\n",
    "            print(f\"  ‚úÖ Best model saved! Val AUC: {val_auc:.4f}\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % SAVE_EVERY == 0 or epoch == cfg.finetune_epochs:\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch, 'classifier': classifier.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict(),\n",
    "                'train_losses': train_losses, 'val_aucs': val_aucs,\n",
    "                'best_auc': best_auc, 'patience_counter': patience_counter,\n",
    "            }, f'{OPTION_NAME}_finetune_latest.pth')\n",
    "        \n",
    "        if patience_counter >= 10:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\n‚úÖ Fine-tuning complete. Best Val AUC: {best_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = os.path.join(CHECKPOINT_DIR, f'{OPTION_NAME}_best_model.pth')\n",
    "checkpoint = load_checkpoint(f'{OPTION_NAME}_best_model.pth')\n",
    "if checkpoint:\n",
    "    classifier.load_state_dict(checkpoint['classifier'])\n",
    "    print(f\"‚úÖ Loaded best model (Val AUC: {checkpoint.get('val_auc', 'N/A')})\")\n",
    "else:\n",
    "    # Fallback to legacy path\n",
    "    legacy_path = checkpoint_dir / 'option6_ssl_best.pth'\n",
    "    if legacy_path.exists():\n",
    "        classifier.load_state_dict(torch.load(legacy_path, map_location=cfg.device, weights_only=False))\n",
    "        print('‚úÖ Loaded best model from legacy path')\n",
    "    else:\n",
    "        print('‚ö†Ô∏è No best model found!')\n",
    "\n",
    "# Evaluate on test set\n",
    "test_auc, disease_aucs = evaluate(classifier, test_loader, cfg.device)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"TEST RESULTS - Option 6 SSL (Segmentation Channel)\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"\\nOverall Test AUC: {test_auc:.4f}\")\n",
    "print(f\"\\nPer-disease AUC scores:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for disease, auc in zip(disease_categories, disease_aucs):\n",
    "    print(f\"{disease:20s}: {auc:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Pretraining loss\n",
    "axes[0].plot(pretrain_losses, 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Contrastive Loss')\n",
    "axes[0].set_title('SSL Pretraining Loss')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Fine-tuning loss\n",
    "axes[1].plot(train_losses, 'g-', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('BCE Loss')\n",
    "axes[1].set_title('Fine-tuning Loss')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation AUC\n",
    "axes[2].plot(val_aucs, 'r-', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('AUC')\n",
    "axes[2].set_title('Validation AUC')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(checkpoint_dir / 'option6_ssl_training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Disease-wise AUC bar plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.8, len(disease_categories)))\n",
    "bars = ax.bar(disease_categories, disease_aucs, color=colors)\n",
    "ax.axhline(y=test_auc, color='red', linestyle='--', linewidth=2, label=f'Mean AUC: {test_auc:.4f}')\n",
    "ax.set_xlabel('Disease')\n",
    "ax.set_ylabel('AUC Score')\n",
    "ax.set_title('Option 6 SSL - Per-Disease AUC Scores')\n",
    "ax.set_ylim(0, 1)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(checkpoint_dir / 'option6_ssl_disease_aucs.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualizations saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Sample Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample predictions\n",
    "classifier.eval()\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i, ax_row in enumerate(axes):\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        idx = i * 4 + j\n",
    "        sample, label = test_dataset[idx]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = torch.sigmoid(classifier(sample.unsqueeze(0).to(cfg.device)))\n",
    "        \n",
    "        # Show original image (channel 0)\n",
    "        ax.imshow(sample[0].numpy(), cmap='gray')\n",
    "        \n",
    "        # Show mask as overlay\n",
    "        mask_overlay = sample[1].numpy()\n",
    "        ax.imshow(mask_overlay, cmap='Reds', alpha=0.3)\n",
    "        \n",
    "        # Get top predictions\n",
    "        pred_np = pred.cpu().numpy().flatten()\n",
    "        top_idx = pred_np.argsort()[-3:][::-1]\n",
    "        \n",
    "        title_lines = []\n",
    "        for tidx in top_idx:\n",
    "            if pred_np[tidx] > 0.3:\n",
    "                title_lines.append(f\"{disease_categories[tidx][:8]}: {pred_np[tidx]:.2f}\")\n",
    "        \n",
    "        ax.set_title('\\n'.join(title_lines) if title_lines else 'No Finding', fontsize=8)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.suptitle('Sample Predictions (Image + Segmentation Overlay)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(checkpoint_dir / 'option6_ssl_samples.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Sample predictions visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implemented **Option 6 with SSL**:\n",
    "\n",
    "1. **2-Channel Input**: Combined grayscale image + rule-based lung segmentation mask\n",
    "2. **SSL Pretraining**: Contrastive learning (NT-Xent loss) to learn representations\n",
    "3. **Fine-tuning**: Multi-label classification for 14 diseases\n",
    "\n",
    "### Key Benefits:\n",
    "- Preserves all original image information\n",
    "- Provides anatomical context through segmentation channel\n",
    "- SSL pretraining helps learn robust features before supervised learning\n",
    "- Consistent augmentations applied to both image and mask channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
