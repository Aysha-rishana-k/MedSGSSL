{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615cfcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üì¶ Step 1: Import Libraries\n",
    "# ============================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import kagglehub\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc32f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìÅ Step 2: Download and Load Dataset\n",
    "# ============================================\n",
    "\n",
    "path = kagglehub.dataset_download(\"khanfashee/nih-chest-x-ray-14-224x224-resized\")\n",
    "BASE_PATH = Path(path)\n",
    "\n",
    "df_labels = pd.read_csv(BASE_PATH / \"Data_Entry_2017.csv\")\n",
    "images_dir = BASE_PATH / \"images-224\" / \"images-224\"\n",
    "df_labels[\"Image Path\"] = [str(images_dir / p) for p in df_labels[\"Image Index\"].values]\n",
    "\n",
    "DISEASE_CATEGORIES = [\n",
    "    'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass',\n",
    "    'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema',\n",
    "    'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'\n",
    "]\n",
    "\n",
    "for disease in DISEASE_CATEGORIES:\n",
    "    df_labels[disease] = df_labels['Finding Labels'].apply(lambda x: 1 if disease in x else 0)\n",
    "\n",
    "sample_paths = df_labels['Image Path'].sample(200, random_state=42).values\n",
    "missing = [p for p in sample_paths if not os.path.exists(p)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(f\"‚ùå Missing {len(missing)} images!\")\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df_labels):,} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ‚öôÔ∏è Step 3: Configuration\n",
    "# ============================================\n",
    "\n",
    "class Config:\n",
    "    img_size = 224\n",
    "    feat_dim = 256\n",
    "    proj_dim = 128\n",
    "    \n",
    "    batch_size = 64\n",
    "    pretrain_epochs = 50\n",
    "    finetune_epochs = 30\n",
    "    lr_pretrain = 1e-3\n",
    "    lr_finetune = 1e-4\n",
    "    temperature = 0.1\n",
    "    pathology_weight = 0.5\n",
    "    \n",
    "    num_workers = 4\n",
    "    use_subset = False\n",
    "    \n",
    "    # Adaptive thresholding params\n",
    "    adaptive_block_size = 11\n",
    "    adaptive_C = 2\n",
    "    gradient_threshold = 0.15\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration:\")\n",
    "print(f\"   Device: {cfg.device}\")\n",
    "print(f\"   Adaptive block size: {cfg.adaptive_block_size}\")\n",
    "print(f\"   Gradient threshold: {cfg.gradient_threshold}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c46557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üíæ Step 3.5: Checkpoint & Resume Configuration\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "OPTION_NAME = \"option3\"\n",
    "\n",
    "# ===== RESUME CONFIGURATION =====\n",
    "CHECKPOINT_DATASET_NAME = \"chest-xray-ssl-checkpoints\"\n",
    "RESUME_SSL_PRETRAINING = False\n",
    "RESUME_FINETUNING = False\n",
    "SSL_CHECKPOINT_FILE = \"latest\"\n",
    "FINETUNE_CHECKPOINT_FILE = \"latest\"\n",
    "\n",
    "IN_KAGGLE = os.path.exists('/kaggle')\n",
    "IN_COLAB = False\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    CHECKPOINT_DIR = '/content/drive/MyDrive/chest_xray_ssl'\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    CHECKPOINT_DIR = '/kaggle/working/checkpoints'\n",
    "    PREV_CHECKPOINT_DIR = f'/kaggle/input/{CHECKPOINT_DATASET_NAME}'\n",
    "    if os.path.exists(PREV_CHECKPOINT_DIR):\n",
    "        print(f\"‚úÖ Found checkpoints at: {PREV_CHECKPOINT_DIR}\")\n",
    "        os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "        for f in os.listdir(PREV_CHECKPOINT_DIR):\n",
    "            if f.endswith('.pth'):\n",
    "                src, dst = os.path.join(PREV_CHECKPOINT_DIR, f), os.path.join(CHECKPOINT_DIR, f)\n",
    "                if not os.path.exists(dst): shutil.copy2(src, dst)\n",
    "elif not IN_COLAB:\n",
    "    CHECKPOINT_DIR = './checkpoints'\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    filepath = os.path.join(CHECKPOINT_DIR, filename)\n",
    "    state['saved_at'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    torch.save(state, filepath)\n",
    "    print(f\"üíæ Saved: {filename}\")\n",
    "    if IN_KAGGLE: torch.save(state, f'/kaggle/working/{filename}')\n",
    "\n",
    "def load_checkpoint(filename):\n",
    "    filepath = os.path.join(CHECKPOINT_DIR, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        checkpoint = torch.load(filepath, map_location=cfg.device)\n",
    "        print(f\"‚úÖ Loaded: {filename}\")\n",
    "        return checkpoint\n",
    "    return None\n",
    "\n",
    "def find_latest_checkpoint(prefix):\n",
    "    if not os.path.exists(CHECKPOINT_DIR): return None\n",
    "    latest = f'{prefix}_latest.pth'\n",
    "    if os.path.exists(os.path.join(CHECKPOINT_DIR, latest)): return latest\n",
    "    import re\n",
    "    pattern = re.compile(rf'{prefix}_epoch(\\d+)\\.pth')\n",
    "    max_epoch, best = -1, None\n",
    "    for f in os.listdir(CHECKPOINT_DIR):\n",
    "        m = pattern.match(f)\n",
    "        if m and int(m.group(1)) > max_epoch: max_epoch, best = int(m.group(1)), f\n",
    "    return best\n",
    "\n",
    "print(f\"üîß Environment: {'Kaggle' if IN_KAGGLE else 'Colab' if IN_COLAB else 'Local'}\")\n",
    "print(f\"üìÇ Checkpoint dir: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d28b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üîç Step 4: Adaptive Pathology Segmentation\n",
    "# ============================================\n",
    "\n",
    "def adaptive_pathology_segmentation(image, block_size=11, C=2, gradient_threshold=0.15, min_size=100):\n",
    "    \"\"\"\n",
    "    Detect potential pathological regions using adaptive thresholding + gradients\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Adaptive thresholding: Detects local high-contrast regions\n",
    "    2. Sobel gradients: Finds edges and region boundaries\n",
    "    3. Combined mask: High local contrast AND edges = likely pathology\n",
    "    \n",
    "    Args:\n",
    "        image: Grayscale image (H, W) or (1, H, W)\n",
    "        block_size: Adaptive thresholding block size\n",
    "        C: Constant subtracted in adaptive thresholding\n",
    "        gradient_threshold: Threshold for gradient magnitude\n",
    "        min_size: Minimum region size to keep (pixels)\n",
    "    \n",
    "    Returns:\n",
    "        Pathology mask (H, W) with values in [0, 1]\n",
    "    \"\"\"\n",
    "    if len(image.shape) == 3 and image.shape[0] == 1:\n",
    "        image = image[0]\n",
    "    \n",
    "    img_uint8 = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    # Adaptive Gaussian thresholding - detects local high-contrast areas\n",
    "    adaptive = cv2.adaptiveThreshold(\n",
    "        img_uint8,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        block_size,\n",
    "        C\n",
    "    )\n",
    "    \n",
    "    # Sobel edge detection for boundaries\n",
    "    sobelx = cv2.Sobel(img_uint8, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(img_uint8, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    \n",
    "    gradient_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    gradient_mag = gradient_mag / (gradient_mag.max() + 1e-8)\n",
    "    gradient_mask = (gradient_mag > gradient_threshold).astype(np.uint8) * 255\n",
    "    \n",
    "    # Combine: regions with BOTH high local contrast AND edges\n",
    "    combined = cv2.bitwise_and(adaptive, gradient_mask)\n",
    "    \n",
    "    # Morphology cleanup\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    combined = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)\n",
    "    combined = cv2.morphologyEx(combined, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Remove small noise regions\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(combined, connectivity=8)\n",
    "    \n",
    "    roi_mask = np.zeros_like(combined)\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_size:\n",
    "            roi_mask[labels == i] = 255\n",
    "    \n",
    "    return roi_mask.astype(np.float32) / 255.0\n",
    "\n",
    "print(\"‚úÖ Adaptive pathology segmentation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fbd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üëÅÔ∏è Step 5: Visualize Pathology Detection\n",
    "# ============================================\n",
    "\n",
    "sample_indices = [0, 100, 500]\n",
    "fig, axes = plt.subplots(len(sample_indices), 4, figsize=(16, 4*len(sample_indices)))\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    img_path = df_labels.iloc[idx]['Image Path']\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    img = img.resize((cfg.img_size, cfg.img_size), Image.LANCZOS)\n",
    "    img_np = np.array(img, dtype=np.float32) / 255.0\n",
    "    \n",
    "    # Get pathology mask\n",
    "    pathology = adaptive_pathology_segmentation(img_np, cfg.adaptive_block_size, \n",
    "                                                cfg.adaptive_C, cfg.gradient_threshold)\n",
    "    \n",
    "    # Adaptive thresholding alone\n",
    "    img_uint8 = (img_np * 255).astype(np.uint8)\n",
    "    adaptive = cv2.adaptiveThreshold(img_uint8, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                      cv2.THRESH_BINARY, cfg.adaptive_block_size, cfg.adaptive_C)\n",
    "    \n",
    "    # Gradient magnitude\n",
    "    sobelx = cv2.Sobel(img_uint8, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(img_uint8, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    gradient_mag = gradient_mag / (gradient_mag.max() + 1e-8)\n",
    "    \n",
    "    # Plot\n",
    "    axes[i, 0].imshow(img_np, cmap='gray')\n",
    "    axes[i, 0].set_title('Original')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(adaptive, cmap='hot')\n",
    "    axes[i, 1].set_title('Adaptive Threshold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    axes[i, 2].imshow(gradient_mag, cmap='hot')\n",
    "    axes[i, 2].set_title('Gradient Magnitude')\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    axes[i, 3].imshow(pathology, cmap='hot')\n",
    "    axes[i, 3].set_title(f'Combined Pathology ({pathology.mean():.1%})')\n",
    "    axes[i, 3].axis('off')\n",
    "\n",
    "plt.suptitle('Option 3: Adaptive Pathology Detection', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('option3_pathology_detection.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d85493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üîÑ Step 6: Augmentation & Datasets\n",
    "# ============================================\n",
    "\n",
    "class ChestXrayAugment:\n",
    "    def __init__(self, img_size=224):\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        if isinstance(img, np.ndarray):\n",
    "            x = torch.tensor(img, dtype=torch.float32)\n",
    "        else:\n",
    "            x = img.clone()\n",
    "        \n",
    "        if random.random() < 0.5:\n",
    "            x = torch.flip(x, dims=[2])\n",
    "        if random.random() < 0.7:\n",
    "            angle = random.uniform(-15, 15)\n",
    "            x = transforms.functional.rotate(x, angle)\n",
    "        if random.random() < 0.8:\n",
    "            factor = 1 + random.uniform(-0.2, 0.2)\n",
    "            x = transforms.functional.adjust_brightness(x, factor)\n",
    "        if random.random() < 0.8:\n",
    "            factor = 1 + random.uniform(-0.2, 0.2)\n",
    "            x = transforms.functional.adjust_contrast(x, factor)\n",
    "        if random.random() < 0.5:\n",
    "            noise = torch.randn_like(x) * 0.05\n",
    "            x = torch.clamp(x + noise, 0, 1)\n",
    "        return x\n",
    "\n",
    "augment = ChestXrayAugment(cfg.img_size)\n",
    "\n",
    "\n",
    "class PathologyAwareDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, img_size=224):\n",
    "        self.df = df.copy().reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        sample_paths = self.df['Image Path'].sample(min(200, len(self.df)), random_state=42).values\n",
    "        missing = [p for p in sample_paths if not os.path.exists(p)]\n",
    "        if missing:\n",
    "            raise FileNotFoundError(f\"‚ùå Missing {len(missing)} images!\")\n",
    "        \n",
    "        print(f\"üì¶ PathologyAwareDataset: {len(self.df)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['Image Path']\n",
    "        \n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img = img.resize((self.img_size, self.img_size), Image.LANCZOS)\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        img = np.expand_dims(img, 0)\n",
    "        \n",
    "        pathology_mask = adaptive_pathology_segmentation(img, cfg.adaptive_block_size, \n",
    "                                                         cfg.adaptive_C, cfg.gradient_threshold)\n",
    "        pathology_mask = np.expand_dims(pathology_mask, 0)\n",
    "        \n",
    "        if self.transform:\n",
    "            view1 = self.transform(img)\n",
    "            view2 = self.transform(img)\n",
    "        else:\n",
    "            view1 = torch.tensor(img, dtype=torch.float32)\n",
    "            view2 = torch.tensor(img, dtype=torch.float32)\n",
    "        \n",
    "        mask = torch.tensor(pathology_mask, dtype=torch.float32)\n",
    "        \n",
    "        return view1, view2, mask\n",
    "\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, df, disease_categories, img_size=224):\n",
    "        self.df = df.copy().reset_index(drop=True)\n",
    "        self.disease_categories = disease_categories\n",
    "        self.img_size = img_size\n",
    "        print(f\"üì¶ ClassificationDataset: {len(self.df)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row['Image Path']).convert('L')\n",
    "        img = img.resize((self.img_size, self.img_size), Image.LANCZOS)\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)\n",
    "        labels = torch.tensor([row[d] for d in self.disease_categories], dtype=torch.float32)\n",
    "        return img, labels\n",
    "\n",
    "print(\"‚úÖ Dataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üèóÔ∏è Step 7: Model Architecture\n",
    "# ============================================\n",
    "\n",
    "def conv_block(in_c, out_c, kernel=3, stride=1, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel, stride, padding),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "def residual_block(channels):\n",
    "    return nn.Sequential(\n",
    "        conv_block(channels, channels),\n",
    "        conv_block(channels, channels)\n",
    "    )\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels=1, feat_dim=256):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            conv_block(in_channels, 64), residual_block(64), nn.MaxPool2d(2),\n",
    "            conv_block(64, 128), residual_block(128), nn.MaxPool2d(2),\n",
    "            conv_block(128, 256), residual_block(256), residual_block(256), nn.MaxPool2d(2),\n",
    "            conv_block(256, 512), residual_block(512), residual_block(512), nn.MaxPool2d(2),\n",
    "            conv_block(512, 512), residual_block(512), nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, feat_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, feat_dim=256, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim), nn.BatchNorm1d(feat_dim), nn.ReLU(),\n",
    "            nn.Linear(feat_dim, proj_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, feat_dim=256, img_size=224):\n",
    "        super().__init__()\n",
    "        self.init_size = img_size // 32\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256 * self.init_size * self.init_size), nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1), nn.BatchNorm2d(16), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 4, 2, 1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = x.view(z.size(0), 256, self.init_size, self.init_size)\n",
    "        return self.decoder(x)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feat_dim=256, num_classes=14):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "encoder = Encoder(feat_dim=cfg.feat_dim).to(cfg.device)\n",
    "proj_head = ProjectionHead(cfg.feat_dim, cfg.proj_dim).to(cfg.device)\n",
    "decoder = Decoder(cfg.feat_dim, cfg.img_size).to(cfg.device)\n",
    "\n",
    "total_params = sum(p.numel() for m in [encoder, proj_head, decoder] for p in m.parameters())\n",
    "print(f\"‚úÖ Models initialized ({total_params:,} parameters)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669fad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üî• Step 8: Loss Functions\n",
    "# ============================================\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature=0.1):\n",
    "    device = z1.device\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    batch_size = z1.shape[0]\n",
    "    representations = torch.cat([z1, z2], dim=0)\n",
    "    similarity = torch.matmul(representations, representations.T) / temperature\n",
    "    mask = torch.eye(2 * batch_size, dtype=torch.bool, device=device)\n",
    "    similarity = similarity.masked_fill(mask, -float('inf'))\n",
    "    labels = torch.cat([torch.arange(batch_size) + batch_size,\n",
    "                        torch.arange(batch_size)]).to(device)\n",
    "    return F.cross_entropy(similarity, labels)\n",
    "\n",
    "\n",
    "def pathology_aware_loss(proj_1, proj_2, pathology_mask_1, pathology_mask_2, \n",
    "                         temperature=0.1, pathology_weight=0.5):\n",
    "    \"\"\"\n",
    "    üéØ KEY INNOVATION: Pathology-aware contrastive loss\n",
    "    \n",
    "    - Base NT-Xent loss\n",
    "    - Emphasizes images with detected pathological regions\n",
    "    - Higher weight for images with clear abnormalities\n",
    "    \"\"\"\n",
    "    base_loss = nt_xent_loss(proj_1, proj_2, temperature)\n",
    "    \n",
    "    path_score_1 = pathology_mask_1.mean(dim=[1, 2, 3])\n",
    "    path_score_2 = pathology_mask_2.mean(dim=[1, 2, 3])\n",
    "    pathology_score = (path_score_1 + path_score_2) / 2\n",
    "    \n",
    "    batch_weights = 1.0 + pathology_weight * pathology_score.to(proj_1.device)\n",
    "    avg_weight = batch_weights.mean()\n",
    "    \n",
    "    return base_loss * avg_weight\n",
    "\n",
    "print(\"‚úÖ Loss functions defined\")\n",
    "print(\"   üéØ pathology_aware_loss: Emphasizes abnormal regions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844bec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìä Step 9: Create Data Loaders\n",
    "# ============================================\n",
    "\n",
    "df_shuffled = df_labels.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_size = int(0.8 * len(df_shuffled))\n",
    "train_df = df_shuffled[:train_size]\n",
    "val_df = df_shuffled[train_size:]\n",
    "\n",
    "train_pretrain_ds = PathologyAwareDataset(train_df, transform=augment, img_size=cfg.img_size)\n",
    "train_class_ds = ClassificationDataset(train_df, DISEASE_CATEGORIES, cfg.img_size)\n",
    "val_class_ds = ClassificationDataset(val_df, DISEASE_CATEGORIES, cfg.img_size)\n",
    "\n",
    "pretrain_loader = DataLoader(\n",
    "    train_pretrain_ds, batch_size=cfg.batch_size, shuffle=True,\n",
    "    num_workers=cfg.num_workers, pin_memory=True, drop_last=True\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_class_ds, batch_size=cfg.batch_size, shuffle=True,\n",
    "    num_workers=cfg.num_workers, pin_memory=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_class_ds, batch_size=cfg.batch_size, shuffle=False,\n",
    "    num_workers=cfg.num_workers, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ DataLoaders ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6155b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üöÄ Step 10: Pathology-Aware SSL Pretraining\n",
    "# ============================================\n",
    "\n",
    "optimizer_ssl = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(proj_head.parameters()) + list(decoder.parameters()),\n",
    "    lr=cfg.lr_pretrain, weight_decay=1e-4\n",
    ")\n",
    "\n",
    "ssl_history = {'loss': [], 'contrastive': [], 'reconstruction': []}\n",
    "START_EPOCH = 1\n",
    "\n",
    "if RESUME_SSL_PRETRAINING:\n",
    "    ckpt_file = find_latest_checkpoint(f'{OPTION_NAME}_ssl') if SSL_CHECKPOINT_FILE == \"latest\" else SSL_CHECKPOINT_FILE\n",
    "    if ckpt_file:\n",
    "        checkpoint = load_checkpoint(ckpt_file)\n",
    "        if checkpoint:\n",
    "            encoder.load_state_dict(checkpoint['encoder'])\n",
    "            proj_head.load_state_dict(checkpoint['proj_head'])\n",
    "            decoder.load_state_dict(checkpoint['decoder'])\n",
    "            if 'optimizer' in checkpoint: optimizer_ssl.load_state_dict(checkpoint['optimizer'])\n",
    "            ssl_history = checkpoint.get('ssl_history', ssl_history)\n",
    "            START_EPOCH = checkpoint['epoch'] + 1\n",
    "            print(f\"üîÑ Resuming from epoch {START_EPOCH}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No checkpoint found. Starting fresh.\")\n",
    "\n",
    "if START_EPOCH > cfg.pretrain_epochs:\n",
    "    print(f\"‚úÖ SSL Pretraining already complete\")\n",
    "else:\n",
    "    print(f\"\\nüöÄ Starting Option 3: Pathology-Aware SSL Pretraining\")\n",
    "    print(f\"   Epochs: {START_EPOCH} ‚Üí {cfg.pretrain_epochs}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for epoch in range(START_EPOCH, cfg.pretrain_epochs + 1):\n",
    "        encoder.train()\n",
    "        proj_head.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        total_loss = total_cont = total_recon = 0\n",
    "        \n",
    "        pbar = tqdm(pretrain_loader, desc=f\"Epoch {epoch}/{cfg.pretrain_epochs}\")\n",
    "        for view1, view2, pathology_mask in pbar:\n",
    "            view1 = view1.to(cfg.device)\n",
    "            view2 = view2.to(cfg.device)\n",
    "            pathology_mask = pathology_mask.to(cfg.device)\n",
    "            \n",
    "            optimizer_ssl.zero_grad()\n",
    "            \n",
    "            z1, z2 = encoder(view1), encoder(view2)\n",
    "            p1, p2 = proj_head(z1), proj_head(z2)\n",
    "            cont_loss = pathology_aware_loss(p1, p2, pathology_mask, pathology_mask, \n",
    "                                             cfg.temperature, cfg.pathology_weight)\n",
    "            \n",
    "            rec1, rec2 = decoder(z1), decoder(z2)\n",
    "            recon_loss = (F.mse_loss(rec1, view1) + F.mse_loss(rec2, view2)) / 2\n",
    "            \n",
    "            loss = cont_loss + 0.5 * recon_loss\n",
    "            loss.backward()\n",
    "            optimizer_ssl.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_cont += cont_loss.item()\n",
    "            total_recon += recon_loss.item()\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        n = len(pretrain_loader)\n",
    "        ssl_history['loss'].append(total_loss / n)\n",
    "        ssl_history['contrastive'].append(total_cont / n)\n",
    "        ssl_history['reconstruction'].append(total_recon / n)\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Loss={total_loss/n:.4f}, Cont={total_cont/n:.4f}, Recon={total_recon/n:.4f}\")\n",
    "        \n",
    "        save_checkpoint({\n",
    "            'epoch': epoch, 'encoder': encoder.state_dict(),\n",
    "            'proj_head': proj_head.state_dict(), 'decoder': decoder.state_dict(),\n",
    "            'optimizer': optimizer_ssl.state_dict(), 'ssl_history': ssl_history,\n",
    "        }, f'{OPTION_NAME}_ssl_latest.pth')\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch, 'encoder': encoder.state_dict(),\n",
    "            'proj_head': proj_head.state_dict(), 'decoder': decoder.state_dict(),\n",
    "            'ssl_history': ssl_history,\n",
    "        }, f'{OPTION_NAME}_ssl_epoch{epoch}.pth')\n",
    "    \n",
    "    print(\"\\n‚úÖ Pathology-Aware SSL Pretraining Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ab3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìà Step 11: Plot SSL Training Curves\n",
    "# ============================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(ssl_history['loss'], 'b-', linewidth=2)\n",
    "axes[0].set_title('Total Loss', fontsize=12)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(ssl_history['contrastive'], 'r-', linewidth=2)\n",
    "axes[1].set_title('Pathology-Aware Contrastive Loss', fontsize=12)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(ssl_history['reconstruction'], 'g-', linewidth=2)\n",
    "axes[2].set_title('Reconstruction Loss', fontsize=12)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Option 3: Pathology-Aware SSL Training', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('option3_ssl_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1aa525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üíæ Step 12: Save Pretrained Model\n",
    "# ============================================\n",
    "\n",
    "torch.save({\n",
    "    'encoder': encoder.state_dict(),\n",
    "    'proj_head': proj_head.state_dict(),\n",
    "    'decoder': decoder.state_dict(),\n",
    "    'config': {'feat_dim': cfg.feat_dim, 'proj_dim': cfg.proj_dim}\n",
    "}, 'option3_ssl_pretrained.pth')\n",
    "\n",
    "print(\"üíæ Pretrained model saved: option3_ssl_pretrained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43f3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üéØ Step 13: Fine-tuning\n",
    "# ============================================\n",
    "\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "encoder.eval()\n",
    "\n",
    "classifier = Classifier(cfg.feat_dim, len(DISEASE_CATEGORIES)).to(cfg.device)\n",
    "\n",
    "pos_counts = train_df[DISEASE_CATEGORIES].sum().values\n",
    "neg_counts = len(train_df) - pos_counts\n",
    "pos_weights = torch.tensor(neg_counts / (pos_counts + 1e-6), dtype=torch.float32).to(cfg.device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "optimizer_ft = torch.optim.Adam(classifier.parameters(), lr=cfg.lr_finetune, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'max', patience=5, factor=0.5)\n",
    "\n",
    "finetune_history = {'train_loss': [], 'train_auc': [], 'val_loss': [], 'val_auc': []}\n",
    "best_val_auc = 0\n",
    "FINETUNE_START_EPOCH = 1\n",
    "\n",
    "if RESUME_FINETUNING:\n",
    "    ckpt_file = find_latest_checkpoint(f'{OPTION_NAME}_finetune') if FINETUNE_CHECKPOINT_FILE == \"latest\" else FINETUNE_CHECKPOINT_FILE\n",
    "    if ckpt_file:\n",
    "        ft_ckpt = load_checkpoint(ckpt_file)\n",
    "        if ft_ckpt:\n",
    "            classifier.load_state_dict(ft_ckpt['classifier'])\n",
    "            if 'optimizer' in ft_ckpt: optimizer_ft.load_state_dict(ft_ckpt['optimizer'])\n",
    "            finetune_history = ft_ckpt.get('finetune_history', finetune_history)\n",
    "            best_val_auc = ft_ckpt.get('best_val_auc', 0)\n",
    "            FINETUNE_START_EPOCH = ft_ckpt['epoch'] + 1\n",
    "            print(f\"üîÑ Resuming fine-tuning from epoch {FINETUNE_START_EPOCH}\")\n",
    "\n",
    "if FINETUNE_START_EPOCH > cfg.finetune_epochs:\n",
    "    print(f\"‚úÖ Fine-tuning already complete\")\n",
    "else:\n",
    "    print(f\"\\nüéØ Starting Fine-tuning: Epochs {FINETUNE_START_EPOCH} ‚Üí {cfg.finetune_epochs}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for epoch in range(FINETUNE_START_EPOCH, cfg.finetune_epochs + 1):\n",
    "        classifier.train()\n",
    "        train_loss = 0\n",
    "        train_preds, train_targets = [], []\n",
    "        \n",
    "        for images, targets in tqdm(train_loader, desc=f\"Train {epoch}/{cfg.finetune_epochs}\"):\n",
    "            images, targets = images.to(cfg.device), targets.to(cfg.device)\n",
    "            optimizer_ft.zero_grad()\n",
    "            with torch.no_grad(): features = encoder(images)\n",
    "            logits = classifier(features)\n",
    "            loss = criterion(logits, targets)\n",
    "            loss.backward()\n",
    "            optimizer_ft.step()\n",
    "            train_loss += loss.item()\n",
    "            train_preds.append(torch.sigmoid(logits).detach().cpu())\n",
    "            train_targets.append(targets.cpu())\n",
    "        \n",
    "        classifier.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_targets = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = images.to(cfg.device)\n",
    "                features = encoder(images)\n",
    "                logits = classifier(features)\n",
    "                loss = criterion(logits, targets)\n",
    "                val_loss += loss.item()\n",
    "                val_preds.append(torch.sigmoid(logits).cpu())\n",
    "                val_targets.append(targets.cpu())\n",
    "        \n",
    "        train_preds, train_targets = torch.cat(train_preds).numpy(), torch.cat(train_targets).numpy()\n",
    "        val_preds, val_targets = torch.cat(val_preds).numpy(), torch.cat(val_targets).numpy()\n",
    "        \n",
    "        train_auc = np.mean([roc_auc_score(train_targets[:, i], train_preds[:, i]) \n",
    "                             for i in range(len(DISEASE_CATEGORIES)) if len(np.unique(train_targets[:, i])) > 1])\n",
    "        val_auc = np.mean([roc_auc_score(val_targets[:, i], val_preds[:, i]) \n",
    "                           for i in range(len(DISEASE_CATEGORIES)) if len(np.unique(val_targets[:, i])) > 1])\n",
    "        \n",
    "        finetune_history['train_loss'].append(train_loss / len(train_loader))\n",
    "        finetune_history['train_auc'].append(train_auc)\n",
    "        finetune_history['val_loss'].append(val_loss / len(val_loader))\n",
    "        finetune_history['val_auc'].append(val_auc)\n",
    "        scheduler.step(val_auc)\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Train AUC={train_auc:.4f}, Val AUC={val_auc:.4f}\")\n",
    "        \n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            save_checkpoint({'encoder': encoder.state_dict(), 'classifier': classifier.state_dict(),\n",
    "                            'val_auc': val_auc, 'epoch': epoch}, f'{OPTION_NAME}_best_model.pth')\n",
    "            print(f\"  ‚úÖ Best model saved! Val AUC: {val_auc:.4f}\")\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == cfg.finetune_epochs:\n",
    "            save_checkpoint({'epoch': epoch, 'classifier': classifier.state_dict(),\n",
    "                            'optimizer': optimizer_ft.state_dict(), 'finetune_history': finetune_history,\n",
    "                            'best_val_auc': best_val_auc}, f'{OPTION_NAME}_finetune_latest.pth')\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Validation AUC: {best_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05601b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìä Step 14: Final Evaluation & Summary\n",
    "# ============================================\n",
    "\n",
    "checkpoint = torch.load('option3_best_model.pth')\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "classifier.load_state_dict(checkpoint['classifier'])\n",
    "\n",
    "encoder.eval()\n",
    "classifier.eval()\n",
    "\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for images, targets in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        images = images.to(cfg.device)\n",
    "        features = encoder(images)\n",
    "        logits = classifier(features)\n",
    "        all_preds.append(torch.sigmoid(logits).cpu())\n",
    "        all_targets.append(targets)\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "print(\"\\nüìä Per-Disease AUC Scores:\")\n",
    "print(\"=\" * 40)\n",
    "auc_scores = []\n",
    "for i, disease in enumerate(DISEASE_CATEGORIES):\n",
    "    if len(np.unique(all_targets[:, i])) > 1:\n",
    "        auc = roc_auc_score(all_targets[:, i], all_preds[:, i])\n",
    "        auc_scores.append((disease, auc))\n",
    "        print(f\"{disease:20s}: {auc:.4f}\")\n",
    "\n",
    "mean_auc = np.mean([a for _, a in auc_scores])\n",
    "print(f\"\\n{'Mean AUC':20s}: {mean_auc:.4f}\")\n",
    "\n",
    "auc_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "diseases, aucs = zip(*auc_scores)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['green' if a >= 0.7 else 'orange' if a >= 0.6 else 'red' for a in aucs]\n",
    "plt.barh(diseases, aucs, color=colors, alpha=0.8)\n",
    "plt.axvline(0.5, color='red', linestyle='--', alpha=0.5, label='Random')\n",
    "plt.axvline(mean_auc, color='blue', linestyle='--', alpha=0.7, label=f'Mean: {mean_auc:.3f}')\n",
    "plt.xlabel('AUC Score')\n",
    "plt.title('Option 3: Per-Disease AUC Performance', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('option3_auc_performance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù OPTION 3: PATHOLOGY-AWARE SSL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Method: Adaptive Thresholding + Gradient-Based Pathology Detection\")\n",
    "print(f\"Key: Emphasizes images with detected abnormal regions\")\n",
    "print(f\"\\nüèÜ Final Mean AUC: {mean_auc:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
