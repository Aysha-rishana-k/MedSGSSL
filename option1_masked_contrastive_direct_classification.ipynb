{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4ac830",
   "metadata": {},
   "source": [
    "import os\nos.environ['OPENCV_LOG_LEVEL'] = 'SILENT'\n",
    "# Option 1 \u2014 Masked Contrastive (direct classification)\n",
    "\n",
    "Direct classification using MobileNetV2 (no SSL pretraining). Keeps dataset, splits, and augmentations from the original option1 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d7ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & config\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# Basic hyperparams (tune as needed)\n",
    "class CFG:\n",
    "    img_size = 224\n",
    "    batch_size = 32\n",
    "    epochs = 8\n",
    "    lr = 1e-4\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    subset_size = None  # set int for faster testing\n",
    "cfg = CFG()\n",
    "print(cfg.device)\n",
    "\n",
    "# Specify your custom folder path here\n",
    "CUSTOM_DATA_PATH = \"datasets\"  # Change this to your desired folder\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(CUSTOM_DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels and image paths (same dataset used previously)\n",
    "# If you're running on Kaggle, the kagglehub helper was used in the original notebooks;\n",
    "# replace with your dataset path if already downloaded.\n",
    "try:\n",
    "    import kagglehub\n",
    "    path = kagglehub.dataset_download(\"khanfashee/nih-chest-x-ray-14-224x224-resized\")\n",
    "    BASE_PATH = Path(path)\n",
    "except Exception:\n",
    "    BASE_PATH = Path('.')  # change to dataset root if needed\n",
    "\n",
    "print(f'Using dataset base: {BASE_PATH}')\n",
    "df = pd.read_csv(BASE_PATH / 'Data_Entry_2017.csv')\n",
    "images_dir = BASE_PATH / 'images-224' / 'images-224'\n",
    "df['Image Path'] = [str(images_dir / p) for p in df['Image Index'].values]\n",
    "\n",
    "DISEASE_CATEGORIES = [\n",
    "    'Atelectasis','Cardiomegaly','Effusion','Infiltration','Mass',\n",
    "    'Nodule','Pneumonia','Pneumothorax','Consolidation','Edema',\n",
    "    'Emphysema','Fibrosis','Pleural_Thickening','Hernia'\n",
    "]\n",
    "for disease in DISEASE_CATEGORIES:\n",
    "    df[disease] = df['Finding Labels'].apply(lambda x: 1 if disease in x else 0)\n",
    "\n",
    "print(f'Loaded {len(df):,} images')\n",
    "print(f'Diseases: {len(DISEASE_CATEGORIES)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient-level split (same logic as originals)\n",
    "from sklearn.model_selection import train_test_split\n",
    "unique_patients = df['Patient ID'].unique()\n",
    "train_val_patients, test_patients = train_test_split(unique_patients, test_size=0.02, random_state=42)\n",
    "train_patients, val_patients = train_test_split(train_val_patients, test_size=0.052, random_state=42)\n",
    "train_df = df[df['Patient ID'].isin(train_patients)].copy()\n",
    "val_df = df[df['Patient ID'].isin(val_patients)].copy()\n",
    "test_df = df[df['Patient ID'].isin(test_patients)].copy()\n",
    "\n",
    "if cfg.subset_size:\n",
    "    train_df = train_df.head(cfg.subset_size)\n",
    "    val_df = val_df.head(cfg.subset_size // 4)\n",
    "    test_df = test_df.head(cfg.subset_size // 8)\n",
    "\n",
    "print('Train/Val/Test sizes:', len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a586bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Step 4: Lung Segmentation (Pre-Computed)\n",
    "# ============================================\n",
    "# Lung segmentation moved to precompute_lung_masks.ipynb\n",
    "# This notebook does not use lung masks for classification.\n",
    "\n",
    "print(\"Lung segmentation handled by precompute_lung_masks.ipynb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2 classifier (adapt for multi-label output)\n",
    "def get_mobilenet_v2(num_classes, pretrained=True):\n",
    "    model = models.mobilenet_v2(pretrained=pretrained)\n",
    "    in_features = model.classifier[1].in_features\n",
    "    # replace classifier with sigmoid multi-label head\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = get_mobilenet_v2(len(DISEASE_CATEGORIES), pretrained=True).to(cfg.device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b65ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training & validation loops\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, targets in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    for imgs, targets in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        all_preds.append(probs)\n",
    "        all_targets.append(targets.numpy())\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "    aucs = []\n",
    "    for i in range(all_targets.shape[1]):\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(all_targets[:, i], all_preds[:, i]))\n",
    "        except Exception:\n",
    "            aucs.append(np.nan)\n",
    "    return np.nanmean(aucs), aucs\n",
    "\n",
    "# Run training (small number of epochs by default)\n",
    "best_auc = 0.0\n",
    "for epoch in range(cfg.epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, cfg.device)\n",
    "    val_auc, per_class = validate(model, val_loader, cfg.device)\n",
    "    print(f'Epoch {epoch+1}/{cfg.epochs} - Train loss: {train_loss:.4f} - Val AUC: {val_auc:.4f}')\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        torch.save(model.state_dict(), 'option1_mobilenetv2_best.pth')\n",
    "\n",
    "print('Training finished. Best val AUC:', best_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e2dcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}